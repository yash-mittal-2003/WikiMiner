{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
},
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -U transformers datasets evaluate optuna seqeval --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "5enZo9J0KfbW",
        "outputId": "fddd200b-8f9a-4c28-a7c4-6e031983ee4b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.6/386.6 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.9/231.9 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOWr0G1ZJyJU",
        "outputId": "ff714fa6-d4a8-4c02-961d-182c919f67b3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###############################################################################\n",
        "# Indic‑NER fine‑tuning on Naamapadam (+ optional custom JSON)\n",
        "###############################################################################\n",
        "import argparse, random, json, os, itertools, logging, collections\n",
        "import numpy as np, torch\n",
        "from datasets import load_dataset, concatenate_datasets, DatasetDict, Sequence, Value\n",
        "import evaluate\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForTokenClassification,\n",
        "    DataCollatorForTokenClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        ")\n",
        "\n",
        "# ──────────────────────────────────────────────────────────────\n",
        "# 0.  LOGGING\n",
        "# ──────────────────────────────────────────────────────────────\n",
        "logging.basicConfig(\n",
        "    format=\"%(asctime)s %(levelname)-8s %(message)s\",\n",
        "    level=logging.INFO,\n",
        "    datefmt=\"%H:%M:%S\",\n",
        ")\n",
        "log = logging.getLogger(__name__)\n",
        "\n",
        "# ──────────────────────────────────────────────────────────────\n",
        "# 1.  ARGUMENTS & SEEDING\n",
        "# ──────────────────────────────────────────────────────────────\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--model_name\", type=str, default=\"ai4bharat/indic-bert\")\n",
        "parser.add_argument(\"--languages\", nargs=\"+\", default=[\"as\"])\n",
        "parser.add_argument(\"--custom_data_path\", type=str, default=\"/content/drive/MyDrive/Yash_final_btp/naamapadam_proj/0.6/0.4/naamapadam_assamese.json\",\n",
        "                    help=\"Path to your extra JSON file (optional)\")\n",
        "parser.add_argument(\"--output_dir\", type=str,\n",
        "                    default=\"./indicner-finetuned-naamapadam\")\n",
        "parser.add_argument(\"--num_train_epochs\", type=int, default=20)\n",
        "parser.add_argument(\"--per_device_train_batch_size\", type=int, default=32)\n",
        "parser.add_argument(\"--per_device_eval_batch_size\", type=int, default=32)\n",
        "parser.add_argument(\"--learning_rate\", type=float, default=1e-5)\n",
        "parser.add_argument(\"--weight_decay\",  type=float, default=0.01)\n",
        "parser.add_argument(\"--warmup_steps\",  type=int, default=500)\n",
        "parser.add_argument(\"--seed\", type=int, default=42)\n",
        "args, _ = parser.parse_known_args()\n",
        "\n",
        "np.random.seed(args.seed)\n",
        "random.seed(args.seed)\n",
        "torch.manual_seed(args.seed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(args.seed)\n",
        "    log.info(\"CUDA device: %s\", torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    log.info(\"CUDA not available – falling back to CPU\")\n",
        "\n",
        "lang = args.languages[0]          # single‑language run\n",
        "\n",
        "# ──────────────────────────────────────────────────────────────\n",
        "# 2.  CANONICAL LABEL SET  (Naamapadam has exactly 7)\n",
        "# ──────────────────────────────────────────────────────────────\n",
        "label_list = [\"B-LOC\",\"B-ORG\",\"B-PER\",\"I-LOC\",\"I-ORG\",\"I-PER\",\"O\"]\n",
        "id2label   = {i:l for i,l in enumerate(label_list)}  # type: ignore\n",
        "label2id   = {l:i for i,l in id2label.items()}\n",
        "num_labels = len(label_list)\n",
        "log.info(\"Canonical labels: %s\", id2label)\n",
        "\n",
        "# Helper – map *any* tag outside this list to “O”\n",
        "def normalise_tag(tag: str) -> str:\n",
        "    tag = str(tag)\n",
        "    if tag in (\"B-PERSON\", \"I-PERSON\"):         # your PERSON alias\n",
        "        tag = tag.replace(\"PERSON\", \"PER\")\n",
        "    return tag if tag in label2id else \"O\"\n",
        "\n",
        "# ──────────────────────────────────────────────────────────────\n",
        "# 3.  LOAD NAAMAPADAM (train / test)\n",
        "# ──────────────────────────────────────────────────────────────\n",
        "train_ref = load_dataset(\"ai4bharat/naamapadam\", lang, split=\"train\")\n",
        "test_ref  = load_dataset(\"ai4bharat/naamapadam\", lang, split=\"test\")\n",
        "\n",
        "# NEW  ➜  make their `ner_tags` column a plain int sequence\n",
        "int_seq = Sequence(Value(\"int64\"))\n",
        "train_ref = train_ref.cast_column(\"ner_tags\", int_seq)\n",
        "test_ref  = test_ref.cast_column(\"ner_tags\", int_seq)\n",
        "\n",
        "# ──────────────────────────────────────────────────────────────\n",
        "# 4.  OPTIONAL: LOAD + CLEAN YOUR CUSTOM JSON\n",
        "# ──────────────────────────────────────────────────────────────\n",
        "if args.custom_data_path:\n",
        "    log.info(\"Loading custom JSON: %s\", args.custom_data_path)\n",
        "    custom = load_dataset(\"json\", data_files=args.custom_data_path,\n",
        "                          split=\"train\")\n",
        "\n",
        "    # (a) ensure tokens / ner_tags length match\n",
        "    broken = [i for i, ex in enumerate(custom)\n",
        "              if len(ex[\"tokens\"]) != len(ex[\"ner_tags\"])]\n",
        "    if broken:\n",
        "        log.warning(\"⚠️  %d rows have mismatching lengths – they’ll be dropped\",\n",
        "                    len(broken))\n",
        "        custom = custom.select([i for i in range(len(custom)) if i not in broken])\n",
        "\n",
        "    # (b) normalise & map to ints\n",
        "    def _clean(batch):\n",
        "        out = []\n",
        "        for tags in batch[\"ner_tags\"]:\n",
        "            out.append([label2id[normalise_tag(t)] for t in tags])\n",
        "        batch[\"ner_tags\"] = out\n",
        "        return batch\n",
        "\n",
        "    custom = custom.map(_clean, batched=True)\n",
        "    log.info(\"Custom set after cleaning: %d sentences\", len(custom))\n",
        "    train_all = concatenate_datasets([train_ref, custom])\n",
        "else:\n",
        "    train_all = train_ref\n",
        "\n",
        "# quick label‑distribution print‑out\n",
        "def label_hist(ds, name):\n",
        "    flat = list(itertools.chain.from_iterable(ds[\"ner_tags\"]))\n",
        "    c = collections.Counter(flat)\n",
        "    log.info(\"%s label distribution: %s\",\n",
        "             name, {id2label[k]: v for k,v in c.items()})\n",
        "label_hist(train_all, \"TRAIN\")\n",
        "label_hist(test_ref,  \"TEST \")\n",
        "\n",
        "# 5. TRAIN / DEV SPLIT ---------------------------------------------------------\n",
        "split = train_all.train_test_split(train_size=0.75, seed=args.seed)\n",
        "train_ds, dev_ds = split[\"train\"], split[\"test\"]\n",
        "log.info(\"Train %d  |  Dev %d  |  Test %d\", len(train_ds), len(dev_ds), len(test_ref))\n",
        "\n",
        "# 6. TOKENISATION + LABEL ALIGNMENT -------------------------------------------\n",
        "tok = AutoTokenizer.from_pretrained(args.model_name, use_fast=True)\n",
        "def align(batch):\n",
        "    enc = tok(batch[\"tokens\"], is_split_into_words=True,\n",
        "              truncation=True, max_length=512)\n",
        "    new_labels = []\n",
        "    for i, seq in enumerate(batch[\"ner_tags\"]):\n",
        "        word_ids = enc.word_ids(batch_index=i)\n",
        "        prev = None\n",
        "        aligned = []\n",
        "        for w in word_ids:\n",
        "            if w is None:\n",
        "                aligned.append(-100)\n",
        "            elif w != prev:\n",
        "                aligned.append(seq[w])\n",
        "            else:\n",
        "                aligned.append(-100)\n",
        "            prev = w\n",
        "        new_labels.append(aligned)\n",
        "    enc[\"labels\"] = new_labels\n",
        "    return enc\n",
        "\n",
        "train_ds = train_ds.map(align, batched=True, remove_columns=[\"ner_tags\"])\n",
        "dev_ds   = dev_ds  .map(align, batched=True, remove_columns=[\"ner_tags\"])\n",
        "test_ref = test_ref.map(align, batched=True, remove_columns=[\"ner_tags\"])\n",
        "\n",
        "# 7. MODEL, METRICS, TRAINER ---------------------------------------------------\n",
        "metric = evaluate.load(\"seqeval\")\n",
        "def compute_metrics(p):\n",
        "    preds, labs = p\n",
        "    preds = np.argmax(preds, axis=2)\n",
        "    true_preds, true_labs = [], []\n",
        "    for pr, lb in zip(preds, labs):\n",
        "        pr_l, lb_l = [], []\n",
        "        for p_i, l_i in zip(pr, lb):\n",
        "            if l_i != -100:\n",
        "                pr_l.append(id2label[p_i])\n",
        "                lb_l.append(id2label[l_i])\n",
        "        true_preds.append(pr_l)\n",
        "        true_labs.append(lb_l)\n",
        "    res = metric.compute(predictions=true_preds, references=true_labs,\n",
        "                         zero_division=0)\n",
        "    return {k.replace(\"overall_\", \"\"): v for k,v in res.items()}\n",
        "\n",
        "model = AutoModelForTokenClassification.from_pretrained(\n",
        "    args.model_name, num_labels=num_labels,\n",
        "    id2label=id2label, label2id=label2id)\n",
        "\n",
        "train_args = TrainingArguments(\n",
        "    output_dir     = args.output_dir,\n",
        "    eval_strategy=\"epoch\",           # ← one eval *after* each epoch\n",
        "    save_strategy  =\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",\n",
        "    num_train_epochs=args.num_train_epochs,\n",
        "    per_device_train_batch_size=args.per_device_train_batch_size,\n",
        "    per_device_eval_batch_size=args.per_device_eval_batch_size,\n",
        "    learning_rate = args.learning_rate,\n",
        "    weight_decay  = args.weight_decay,\n",
        "    warmup_steps  = args.warmup_steps,\n",
        "    seed = args.seed,\n",
        "    fp16 = torch.cuda.is_available(),\n",
        "    report_to=\"none\")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=train_args,\n",
        "    train_dataset=train_ds,\n",
        "    eval_dataset =dev_ds,\n",
        "    tokenizer=tok,\n",
        "    data_collator=DataCollatorForTokenClassification(tok),\n",
        "    compute_metrics=compute_metrics)\n",
        "\n",
        "# 8. TRAIN & FINAL EVALUATION --------------------------------------------------\n",
        "log.info(\"⏳  Starting fine‑tuning …\")\n",
        "trainer.train()\n",
        "log.info(\"✅  Finished training.  Best dev‑set F1: %.4f\",\n",
        "         trainer.state.best_metric or -1)\n",
        "\n",
        "log.info(\"🏁  Test‑set metrics:\")\n",
        "print(trainer.evaluate(eval_dataset=test_ref))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "029d779fe5684732bd82a753c4ce5af0",
            "c6192649092a4ac1bdc8897a59037f6d",
            "589361a7b22c4cf991f2968f0f95ae1a",
            "3e69556564194c959c1ec693da1af353",
            "bb3e8ef2415645cca0722c1449a0fd7d",
            "102700be95f84a189f93dd9c9228e690",
            "4e35a360148b4782955e29f7109166be",
            "b10be045be544c688aacfa7bf3c15216",
            "95f1028d5a074132b53bd305df1fe995",
            "c6ceb126d16a431faf921d2de070f93a",
            "33da033a4adf456c9d8bc575c40b3290",
            "50ead510516647948f49aa3fe1768a21",
            "7b9e1b75e6ea4605aa876164c30a9577",
            "ec62cfe9f6784df08b8dc5451e7229e4",
            "9cca786498314344abcbb9c4509c8359",
            "aa8ad4b898c9412690699a0a12f00bdb",
            "d91d919bcd0b471caa89ec6d52f531cf",
            "7f3ad826915c4ce6905dbe800502b38b",
            "5369d2841ace4f0795c3ea248bd246de",
            "70c45338d30047f0b8a6ea971e840031",
            "d1f63a32b883400b9fa12eee1a1fec22",
            "cde723272be34c8f86eaed9b640e62ed",
            "833f9ff3837a4d9fa14818d7726007cc",
            "17120197b4604c4cb60114678304000d",
            "c37399794d55432783c6f274517bbf42",
            "0a6a51549991456a8df87ead97fef23c",
            "31f12ce3a092405ab4b12aa46a9e31ad",
            "6f7f9653162143ceb25e55151e698835",
            "e6332dc2b5374617878223a39aae9217",
            "6e36c6677ae148b09031bb55028a6bb3",
            "4a95ac00d3ae47dea3f8804a6eecab7c",
            "a0a8b9ea1b2c4e3c9e349b6181eccc53",
            "adc0c022e67543cb802caf230b0c1e58",
            "923448509ab5409096d97a81ee82bed0",
            "c124e1da829a47c28762d1b48f40e36f",
            "4cb4da46abbc4f73bc0024d5fdd7ff59",
            "bf1111f7208a46d7bcca1bd8b0b929cf",
            "385690b44e39475395145907c6eec2fd",
            "cbc3ede093024207877c3da983cbc0e2",
            "d842e1586f614cf78b491995d09f40fd",
            "78f66bd479fb4fbfacd248d8fed4df9a",
            "8691b00de6504608950d0a1005592e54",
            "6500b8faf57248daa532fdf716df4558",
            "8392634e78924e76aa3ce5a9ec3604e9",
            "d4ade13f0e02428cb5cc50335eb1c1be",
            "8e18904b33154078bd3af18d3559daa5",
            "412ba59e0edc4f47a545769661718c1c",
            "ab41e15ba7e54a8cbdb6dc6004a1280e",
            "49b2ee956fd84d16bc58c84c560cf2a2",
            "6dc3966fef24491eb73e4a82fc7cd15b",
            "1e74d7c38f9a4b67b9311de94c587066",
            "462684e7010e43e49517d00a942a7772",
            "9ac5b7ca0b2f47d7bd42bb107bdddc70",
            "3dee75766ffe4d7da0da21bec8c189c5",
            "469ecb87cd2440ca8df0453c158c08a8",
            "735d504e3b014087a61e168af236e19c",
            "5bdce73bf6ae428798fb92494a468fb4",
            "bb5d905784534bed81c685041ae38190",
            "a0efbfd46a00444088252bceb343c4a6",
            "4e7f14afd3314bb68b96d887bf6d6a99",
            "4e80a0c534d14d73a479bf41aea06c75",
            "6ec86bb42ea848e58bd352dc6a14e301",
            "f1ceb74034ba496d8d65cb66de80310f",
            "ad2ae7c2790a4a3ca6e7bbc8f5e80265",
            "c03f61d979004d8a9924c83038a2dd35",
            "1ccabf63a2d24691a00de012106f1f94",
            "5bb07c1079ad4f08a9bb7603d506b37c",
            "fba0269fbeab42cf9c3317a2a10dce52",
            "8e5d21680ca24e4aa59f6b63715cfc53",
            "938f1d8a1d1340f18583c14b9323dc08",
            "7cc6e38b6b5249daaae81dabfc151fd1",
            "e615e0e35185486ebf4e97334b0402b4",
            "05b0197b8cb84f3abae1f02780d5b862",
            "321ddec307644b95bb86044ec44ea90d",
            "570a15ef72694908a21a16525fccaacb",
            "65a7d107a6084e1a8a665acb60352620",
            "65a85c4b605540b4a9dc674ad181971a",
            "e23798a5bb3c4734aac4b7625049652d",
            "ce1f1978800949308fd6fdcafcebf5dc",
            "4336bd9329904116ad04e8ce97e2def1",
            "3d21211b6186440eb973a1737c22cdb7",
            "663744460b6c49a1922d767f8c95bbc2",
            "e5ef8881147147ccb02eed6906758bec",
            "b332b83558734b5ba4baf38447bd007c",
            "5ad3be2ddc714129b2e5671688919f4c",
            "8f083f861bf0461997a5639608bf6e1c",
            "7999fc98a48742a8a08d7577fe706290",
            "8fbde4b381b4466fbbd6533e8e5a6b5c",
            "3eb4f3b63ca044c7b9d93dca1a7d1459",
            "5b507db2c04c4ab08df4cb84caccd7e3",
            "2d0e7ae87c7b4ff29d1713acbfb1ae5e",
            "b707373b1e6447b3b062c400031345d0",
            "a355b443b315441086665ef6cae47c94",
            "d73d988c265e4b5fa20990f23e19917b",
            "ba40520995c0462099901dc8817154f4",
            "3863906d8d3d49f19a9439e87dfba340",
            "3282484664c949ba8d8bccc8c738385e",
            "2af6ef344900465aabcf1197a2ea2ca1",
            "ee73f25741f042449eb5607c96d0fdf6",
            "3a18778dbe964f338639815efc54d794",
            "8afe105b8e79421cbe213f6907659173",
            "1652ff75db934ce698392c8f751e4873",
            "09bb8dd493a247efbfed5ae70d1d7a8c",
            "20be557f8c714d15a0f6d8686a5f1339",
            "8c4ea53541274a1c8704d5c3ab69f163",
            "bb67aacc99d946ff8e6bdcce2e9b3f12",
            "4abf75c476cd45edbec00658d57b5b81",
            "010a0d0162de422c898b28414b5a345b",
            "d5322e5e53994a50a4507e2164a85edb",
            "c167472c05dd4cac89ec96c8cbba3ffe"
          ]
        },
        "id": "NCWymXFdRS4g",
        "outputId": "41514051-a4c3-4e48-ed2b-9404881f67aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "029d779fe5684732bd82a753c4ce5af0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1437 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "50ead510516647948f49aa3fe1768a21"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/507 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "833f9ff3837a4d9fa14818d7726007cc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/5.65M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "923448509ab5409096d97a81ee82bed0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/8777 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d4ade13f0e02428cb5cc50335eb1c1be"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2926 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "735d504e3b014087a61e168af236e19c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/51 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5bb07c1079ad4f08a9bb7603d506b37c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/6.34k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e23798a5bb3c4734aac4b7625049652d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/135M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3eb4f3b63ca044c7b9d93dca1a7d1459"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of AlbertForTokenClassification were not initialized from the model checkpoint at ai4bharat/indic-bert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-5-0eec3401fe9a>:192: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5500' max='5500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5500/5500 13:07, Epoch 20/20]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Loc</th>\n",
              "      <th>Org</th>\n",
              "      <th>Per</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.761701</td>\n",
              "      <td>{'precision': 0.7509477104518925, 'recall': 0.9824064234266147, 'f1': 0.8512234632108449, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 773}</td>\n",
              "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1087}</td>\n",
              "      <td>0.750948</td>\n",
              "      <td>0.915392</td>\n",
              "      <td>0.825056</td>\n",
              "      <td>0.755246</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.984600</td>\n",
              "      <td>0.692770</td>\n",
              "      <td>{'precision': 0.796678765297273, 'recall': 0.9762270240484906, 'f1': 0.8773611602405378, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 773}</td>\n",
              "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1087}</td>\n",
              "      <td>0.796679</td>\n",
              "      <td>0.909634</td>\n",
              "      <td>0.849418</td>\n",
              "      <td>0.801410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.984600</td>\n",
              "      <td>0.628235</td>\n",
              "      <td>{'precision': 0.8984942570721214, 'recall': 0.8713346715472114, 'f1': 0.884706070415218, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 773}</td>\n",
              "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1087}</td>\n",
              "      <td>0.898494</td>\n",
              "      <td>0.811897</td>\n",
              "      <td>0.853004</td>\n",
              "      <td>0.811146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.581000</td>\n",
              "      <td>0.579840</td>\n",
              "      <td>{'precision': 0.8786852293031566, 'recall': 0.9290746644625497, 'f1': 0.9031776702186682, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 773}</td>\n",
              "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1087}</td>\n",
              "      <td>0.878685</td>\n",
              "      <td>0.865698</td>\n",
              "      <td>0.872144</td>\n",
              "      <td>0.836954</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.581000</td>\n",
              "      <td>0.581730</td>\n",
              "      <td>{'precision': 0.8437489144405461, 'recall': 0.9559963789506829, 'f1': 0.8963722921356608, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 773}</td>\n",
              "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1087}</td>\n",
              "      <td>0.843720</td>\n",
              "      <td>0.890784</td>\n",
              "      <td>0.866613</td>\n",
              "      <td>0.831701</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.461800</td>\n",
              "      <td>0.563691</td>\n",
              "      <td>{'precision': 0.8604154809334092, 'recall': 0.9520210965481953, 'f1': 0.9039032866832339, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.125, 'recall': 0.00129366106080207, 'f1': 0.0025608194622279133, 'number': 773}</td>\n",
              "      <td>{'precision': 0.5882352941176471, 'recall': 0.00919963201471941, 'f1': 0.018115942028985504, 'number': 1087}</td>\n",
              "      <td>0.860042</td>\n",
              "      <td>0.887483</td>\n",
              "      <td>0.873547</td>\n",
              "      <td>0.842864</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.461800</td>\n",
              "      <td>0.571060</td>\n",
              "      <td>{'precision': 0.885239755558055, 'recall': 0.9293501790845042, 'f1': 0.9067588325652842, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 773}</td>\n",
              "      <td>{'precision': 0.7122302158273381, 'recall': 0.09107635694572216, 'f1': 0.16150081566068517, 'number': 1087}</td>\n",
              "      <td>0.883914</td>\n",
              "      <td>0.869586</td>\n",
              "      <td>0.876692</td>\n",
              "      <td>0.845776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.377800</td>\n",
              "      <td>0.578216</td>\n",
              "      <td>{'precision': 0.8779059057583908, 'recall': 0.9378911323650962, 'f1': 0.9069077069457661, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.2, 'recall': 0.009055627425614488, 'f1': 0.017326732673267325, 'number': 773}</td>\n",
              "      <td>{'precision': 0.601593625498008, 'recall': 0.1389144434222631, 'f1': 0.2257100149476831, 'number': 1087}</td>\n",
              "      <td>0.874512</td>\n",
              "      <td>0.879708</td>\n",
              "      <td>0.877103</td>\n",
              "      <td>0.846433</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.377800</td>\n",
              "      <td>0.625349</td>\n",
              "      <td>{'precision': 0.8630107832009081, 'recall': 0.9576101074507025, 'f1': 0.9078527584469859, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.2727272727272727, 'recall': 0.007761966364812419, 'f1': 0.01509433962264151, 'number': 773}</td>\n",
              "      <td>{'precision': 0.5927272727272728, 'recall': 0.1499540018399264, 'f1': 0.23935389133627025, 'number': 1087}</td>\n",
              "      <td>0.859946</td>\n",
              "      <td>0.898485</td>\n",
              "      <td>0.878793</td>\n",
              "      <td>0.847403</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.315500</td>\n",
              "      <td>0.575456</td>\n",
              "      <td>{'precision': 0.8923216034963454, 'recall': 0.9321840437674657, 'f1': 0.9118173593331921, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.16666666666666666, 'recall': 0.031047865459249677, 'f1': 0.05234460196292257, 'number': 773}</td>\n",
              "      <td>{'precision': 0.40589569160997735, 'recall': 0.32934682612695493, 'f1': 0.3636363636363637, 'number': 1087}</td>\n",
              "      <td>0.872969</td>\n",
              "      <td>0.882605</td>\n",
              "      <td>0.877761</td>\n",
              "      <td>0.846433</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.268500</td>\n",
              "      <td>0.586040</td>\n",
              "      <td>{'precision': 0.9172479391249208, 'recall': 0.9109300586452552, 'f1': 0.9140780821106262, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.40131578947368424, 'recall': 0.07891332470892626, 'f1': 0.13189189189189188, 'number': 773}</td>\n",
              "      <td>{'precision': 0.5564356435643565, 'recall': 0.25850965961361544, 'f1': 0.3530150753768844, 'number': 1087}</td>\n",
              "      <td>0.907181</td>\n",
              "      <td>0.861334</td>\n",
              "      <td>0.883663</td>\n",
              "      <td>0.854255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.268500</td>\n",
              "      <td>0.554664</td>\n",
              "      <td>{'precision': 0.9073974289893003, 'recall': 0.9279332467430236, 'f1': 0.9175504485395708, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.3539518900343643, 'recall': 0.1332470892626132, 'f1': 0.19360902255639098, 'number': 773}</td>\n",
              "      <td>{'precision': 0.5130168453292496, 'recall': 0.30818767249310025, 'f1': 0.3850574712643678, 'number': 1087}</td>\n",
              "      <td>0.891852</td>\n",
              "      <td>0.880698</td>\n",
              "      <td>0.886240</td>\n",
              "      <td>0.857310</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.241500</td>\n",
              "      <td>0.571860</td>\n",
              "      <td>{'precision': 0.8945607638236289, 'recall': 0.9366709961821545, 'f1': 0.9151317054412613, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.2930513595166163, 'recall': 0.12548512289780078, 'f1': 0.17572463768115942, 'number': 773}</td>\n",
              "      <td>{'precision': 0.46134969325153374, 'recall': 0.34590616375344985, 'f1': 0.3953732912723449, 'number': 1087}</td>\n",
              "      <td>0.874662</td>\n",
              "      <td>0.890124</td>\n",
              "      <td>0.882325</td>\n",
              "      <td>0.852000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.241500</td>\n",
              "      <td>0.592899</td>\n",
              "      <td>{'precision': 0.8854990164421186, 'recall': 0.9390325500846224, 'f1': 0.9114804202483285, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.3614864864864865, 'recall': 0.1384217335058215, 'f1': 0.20018709073900842, 'number': 773}</td>\n",
              "      <td>{'precision': 0.5216763005780347, 'recall': 0.33210671573137074, 'f1': 0.4058459808881394, 'number': 1087}</td>\n",
              "      <td>0.870932</td>\n",
              "      <td>0.892141</td>\n",
              "      <td>0.881409</td>\n",
              "      <td>0.848831</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.219300</td>\n",
              "      <td>0.584558</td>\n",
              "      <td>{'precision': 0.9016125351791283, 'recall': 0.933089306096745, 'f1': 0.9170809075259666, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.37388724035608306, 'recall': 0.1630012936610608, 'f1': 0.22702702702702704, 'number': 773}</td>\n",
              "      <td>{'precision': 0.5522151898734177, 'recall': 0.32106715731370744, 'f1': 0.40605002908667825, 'number': 1087}</td>\n",
              "      <td>0.886990</td>\n",
              "      <td>0.886860</td>\n",
              "      <td>0.886925</td>\n",
              "      <td>0.856996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.219300</td>\n",
              "      <td>0.588006</td>\n",
              "      <td>{'precision': 0.8964734372635084, 'recall': 0.932498917621128, 'f1': 0.9141313784122698, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.33505154639175255, 'recall': 0.16817593790426907, 'f1': 0.2239448751076658, 'number': 773}</td>\n",
              "      <td>{'precision': 0.5078459343794579, 'recall': 0.32750689972401104, 'f1': 0.39821029082774045, 'number': 1087}</td>\n",
              "      <td>0.878657</td>\n",
              "      <td>0.886713</td>\n",
              "      <td>0.882666</td>\n",
              "      <td>0.851058</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.202000</td>\n",
              "      <td>0.607247</td>\n",
              "      <td>{'precision': 0.8896817095038853, 'recall': 0.9373401031211871, 'f1': 0.9128893148059416, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.3425, 'recall': 0.17723156532988357, 'f1': 0.23358908780903667, 'number': 773}</td>\n",
              "      <td>{'precision': 0.484375, 'recall': 0.3422263109475621, 'f1': 0.401078167115903, 'number': 1087}</td>\n",
              "      <td>0.870704</td>\n",
              "      <td>0.892067</td>\n",
              "      <td>0.881256</td>\n",
              "      <td>0.848917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.202000</td>\n",
              "      <td>0.589604</td>\n",
              "      <td>{'precision': 0.9002208850635997, 'recall': 0.930373519108907, 'f1': 0.9150488725442757, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.3042505592841163, 'recall': 0.1759379042690815, 'f1': 0.22295081967213115, 'number': 773}</td>\n",
              "      <td>{'precision': 0.4899598393574297, 'recall': 0.33670653173873044, 'f1': 0.39912758996728465, 'number': 1087}</td>\n",
              "      <td>0.879353</td>\n",
              "      <td>0.885319</td>\n",
              "      <td>0.882326</td>\n",
              "      <td>0.851629</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.187700</td>\n",
              "      <td>0.607103</td>\n",
              "      <td>{'precision': 0.8927845910766684, 'recall': 0.9340732868894399, 'f1': 0.9129623574217623, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.317016317016317, 'recall': 0.1759379042690815, 'f1': 0.22628951747088188, 'number': 773}</td>\n",
              "      <td>{'precision': 0.4939919893190921, 'recall': 0.3403863845446182, 'f1': 0.40305010893246196, 'number': 1087}</td>\n",
              "      <td>0.873127</td>\n",
              "      <td>0.888913</td>\n",
              "      <td>0.880949</td>\n",
              "      <td>0.848317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.179500</td>\n",
              "      <td>0.601564</td>\n",
              "      <td>{'precision': 0.8952402555668972, 'recall': 0.9320266068406344, 'f1': 0.9132631416560608, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.32265446224256294, 'recall': 0.18240620957309184, 'f1': 0.23305785123966943, 'number': 773}</td>\n",
              "      <td>{'precision': 0.4794344473007712, 'recall': 0.34314627414903404, 'f1': 0.39999999999999997, 'number': 1087}</td>\n",
              "      <td>0.874503</td>\n",
              "      <td>0.887300</td>\n",
              "      <td>0.880855</td>\n",
              "      <td>0.848745</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/135M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3a18778dbe964f338639815efc54d794"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2/2 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.47220128774642944, 'eval_LOC': {'precision': 0.9475890985324947, 'recall': 0.9094567404426559, 'f1': 0.9281314168377824, 'number': 497}, 'eval_ORG': {'precision': 0.4, 'recall': 0.2222222222222222, 'f1': 0.2857142857142857, 'number': 9}, 'eval_PER': {'precision': 1.0, 'recall': 0.09090909090909091, 'f1': 0.16666666666666669, 'number': 11}, 'eval_precision': 0.9420289855072463, 'eval_recall': 0.8800773694390716, 'eval_f1': 0.9099999999999999, 'eval_accuracy': 0.8861940298507462, 'eval_runtime': 0.0976, 'eval_samples_per_second': 522.305, 'eval_steps_per_second': 20.483, 'epoch': 20.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###############################################################################\n",
        "# Indic‑NER fine‑tuning on Naamapadam (+ optional custom JSON)\n",
        "###############################################################################\n",
        "import argparse, random, json, os, itertools, logging, collections\n",
        "import numpy as np, torch\n",
        "from datasets import load_dataset, concatenate_datasets, DatasetDict, Sequence, Value\n",
        "import evaluate\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForTokenClassification,\n",
        "    DataCollatorForTokenClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        ")\n",
        "\n",
        "# ──────────────────────────────────────────────────────────────\n",
        "# 0.  LOGGING\n",
        "# ──────────────────────────────────────────────────────────────\n",
        "logging.basicConfig(\n",
        "    format=\"%(asctime)s %(levelname)-8s %(message)s\",\n",
        "    level=logging.INFO,\n",
        "    datefmt=\"%H:%M:%S\",\n",
        ")\n",
        "log = logging.getLogger(__name__)\n",
        "\n",
        "# ──────────────────────────────────────────────────────────────\n",
        "# 1.  ARGUMENTS & SEEDING\n",
        "# ──────────────────────────────────────────────────────────────\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--model_name\", type=str, default=\"ai4bharat/indic-bert\")\n",
        "parser.add_argument(\"--languages\", nargs=\"+\", default=[\"as\"])\n",
        "parser.add_argument(\"--custom_data_path\", type=str, default=None,\n",
        "                    help=\"Path to your extra JSON file (optional)\")\n",
        "parser.add_argument(\"--output_dir\", type=str,\n",
        "                    default=\"./indicner-finetuned-naamapadam\")\n",
        "parser.add_argument(\"--num_train_epochs\", type=int, default=5)\n",
        "parser.add_argument(\"--per_device_train_batch_size\", type=int, default=32)\n",
        "parser.add_argument(\"--per_device_eval_batch_size\", type=int, default=32)\n",
        "parser.add_argument(\"--learning_rate\", type=float, default=3e-5)\n",
        "parser.add_argument(\"--weight_decay\",  type=float, default=0.01)\n",
        "parser.add_argument(\"--warmup_steps\",  type=int, default=500)\n",
        "parser.add_argument(\"--seed\", type=int, default=42)\n",
        "args, _ = parser.parse_known_args()\n",
        "\n",
        "np.random.seed(args.seed)\n",
        "random.seed(args.seed)\n",
        "torch.manual_seed(args.seed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(args.seed)\n",
        "    log.info(\"CUDA device: %s\", torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    log.info(\"CUDA not available – falling back to CPU\")\n",
        "\n",
        "lang = args.languages[0]          # single‑language run\n",
        "\n",
        "# ──────────────────────────────────────────────────────────────\n",
        "# 2.  CANONICAL LABEL SET  (Naamapadam has exactly 7)\n",
        "# ──────────────────────────────────────────────────────────────\n",
        "label_list = [\"B-LOC\",\"B-ORG\",\"B-PER\",\"I-LOC\",\"I-ORG\",\"I-PER\",\"O\"]\n",
        "id2label   = {i:l for i,l in enumerate(label_list)}  # type: ignore\n",
        "label2id   = {l:i for i,l in id2label.items()}\n",
        "num_labels = len(label_list)\n",
        "log.info(\"Canonical labels: %s\", id2label)\n",
        "\n",
        "# Helper – map *any* tag outside this list to “O”\n",
        "def normalise_tag(tag: str) -> str:\n",
        "    tag = str(tag)\n",
        "    if tag in (\"B-PERSON\", \"I-PERSON\"):         # your PERSON alias\n",
        "        tag = tag.replace(\"PERSON\", \"PER\")\n",
        "    return tag if tag in label2id else \"O\"\n",
        "\n",
        "# ──────────────────────────────────────────────────────────────\n",
        "# 3.  LOAD NAAMAPADAM (train / test)\n",
        "# ──────────────────────────────────────────────────────────────\n",
        "train_ref = load_dataset(\"ai4bharat/naamapadam\", lang, split=\"train\")\n",
        "test_ref  = load_dataset(\"ai4bharat/naamapadam\", lang, split=\"test\")\n",
        "\n",
        "# NEW  ➜  make their `ner_tags` column a plain int sequence\n",
        "int_seq = Sequence(Value(\"int64\"))\n",
        "train_ref = train_ref.cast_column(\"ner_tags\", int_seq)\n",
        "test_ref  = test_ref.cast_column(\"ner_tags\", int_seq)\n",
        "\n",
        "# ──────────────────────────────────────────────────────────────\n",
        "# 4.  OPTIONAL: LOAD + CLEAN YOUR CUSTOM JSON\n",
        "# ──────────────────────────────────────────────────────────────\n",
        "if args.custom_data_path:\n",
        "    log.info(\"Loading custom JSON: %s\", args.custom_data_path)\n",
        "    custom = load_dataset(\"json\", data_files=args.custom_data_path,\n",
        "                          split=\"train\")\n",
        "\n",
        "    # (a) ensure tokens / ner_tags length match\n",
        "    broken = [i for i, ex in enumerate(custom)\n",
        "              if len(ex[\"tokens\"]) != len(ex[\"ner_tags\"])]\n",
        "    if broken:\n",
        "        log.warning(\"⚠️  %d rows have mismatching lengths – they’ll be dropped\",\n",
        "                    len(broken))\n",
        "        custom = custom.select([i for i in range(len(custom)) if i not in broken])\n",
        "\n",
        "    # (b) normalise & map to ints\n",
        "    def _clean(batch):\n",
        "        out = []\n",
        "        for tags in batch[\"ner_tags\"]:\n",
        "            out.append([label2id[normalise_tag(t)] for t in tags])\n",
        "        batch[\"ner_tags\"] = out\n",
        "        return batch\n",
        "\n",
        "    custom = custom.map(_clean, batched=True)\n",
        "    log.info(\"Custom set after cleaning: %d sentences\", len(custom))\n",
        "    train_all = concatenate_datasets([train_ref, custom])\n",
        "else:\n",
        "    train_all = train_ref\n",
        "\n",
        "# quick label‑distribution print‑out\n",
        "def label_hist(ds, name):\n",
        "    flat = list(itertools.chain.from_iterable(ds[\"ner_tags\"]))\n",
        "    c = collections.Counter(flat)\n",
        "    log.info(\"%s label distribution: %s\",\n",
        "             name, {id2label[k]: v for k,v in c.items()})\n",
        "label_hist(train_all, \"TRAIN\")\n",
        "label_hist(test_ref,  \"TEST \")\n",
        "\n",
        "# 5. TRAIN / DEV SPLIT ---------------------------------------------------------\n",
        "split = train_all.train_test_split(train_size=0.75, seed=args.seed)\n",
        "train_ds, dev_ds = split[\"train\"], split[\"test\"]\n",
        "log.info(\"Train %d  |  Dev %d  |  Test %d\", len(train_ds), len(dev_ds), len(test_ref))\n",
        "\n",
        "# 6. TOKENISATION + LABEL ALIGNMENT -------------------------------------------\n",
        "tok = AutoTokenizer.from_pretrained(args.model_name, use_fast=True)\n",
        "def align(batch):\n",
        "    enc = tok(batch[\"tokens\"], is_split_into_words=True,\n",
        "              truncation=True, max_length=512)\n",
        "    new_labels = []\n",
        "    for i, seq in enumerate(batch[\"ner_tags\"]):\n",
        "        word_ids = enc.word_ids(batch_index=i)\n",
        "        prev = None\n",
        "        aligned = []\n",
        "        for w in word_ids:\n",
        "            if w is None:\n",
        "                aligned.append(-100)\n",
        "            elif w != prev:\n",
        "                aligned.append(seq[w])\n",
        "            else:\n",
        "                aligned.append(-100)\n",
        "            prev = w\n",
        "        new_labels.append(aligned)\n",
        "    enc[\"labels\"] = new_labels\n",
        "    return enc\n",
        "\n",
        "train_ds = train_ds.map(align, batched=True, remove_columns=[\"ner_tags\"])\n",
        "dev_ds   = dev_ds  .map(align, batched=True, remove_columns=[\"ner_tags\"])\n",
        "test_ref = test_ref.map(align, batched=True, remove_columns=[\"ner_tags\"])\n",
        "\n",
        "# 7. MODEL, METRICS, TRAINER ---------------------------------------------------\n",
        "metric = evaluate.load(\"seqeval\")\n",
        "def compute_metrics(p):\n",
        "    preds, labs = p\n",
        "    preds = np.argmax(preds, axis=2)\n",
        "    true_preds, true_labs = [], []\n",
        "    for pr, lb in zip(preds, labs):\n",
        "        pr_l, lb_l = [], []\n",
        "        for p_i, l_i in zip(pr, lb):\n",
        "            if l_i != -100:\n",
        "                pr_l.append(id2label[p_i])\n",
        "                lb_l.append(id2label[l_i])\n",
        "        true_preds.append(pr_l)\n",
        "        true_labs.append(lb_l)\n",
        "    res = metric.compute(predictions=true_preds, references=true_labs,\n",
        "                         zero_division=0)\n",
        "    return {k.replace(\"overall_\", \"\"): v for k,v in res.items()}\n",
        "\n",
        "model = AutoModelForTokenClassification.from_pretrained(\n",
        "    args.model_name, num_labels=num_labels,\n",
        "    id2label=id2label, label2id=label2id)\n",
        "\n",
        "train_args = TrainingArguments(\n",
        "    output_dir     = args.output_dir,\n",
        "    eval_strategy=\"epoch\",           # ← one eval *after* each epoch\n",
        "    save_strategy  =\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",\n",
        "    num_train_epochs=args.num_train_epochs,\n",
        "    per_device_train_batch_size=args.per_device_train_batch_size,\n",
        "    per_device_eval_batch_size=args.per_device_eval_batch_size,\n",
        "    learning_rate = args.learning_rate,\n",
        "    weight_decay  = args.weight_decay,\n",
        "    warmup_steps  = args.warmup_steps,\n",
        "    seed = args.seed,\n",
        "    fp16 = torch.cuda.is_available(),\n",
        "    report_to=\"none\")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=train_args,\n",
        "    train_dataset=train_ds,\n",
        "    eval_dataset =dev_ds,\n",
        "    tokenizer=tok,\n",
        "    data_collator=DataCollatorForTokenClassification(tok),\n",
        "    compute_metrics=compute_metrics)\n",
        "\n",
        "# 8. TRAIN & FINAL EVALUATION --------------------------------------------------\n",
        "log.info(\"⏳  Starting fine‑tuning …\")\n",
        "trainer.train()\n",
        "log.info(\"✅  Finished training.  Best dev‑set F1: %.4f\",\n",
        "         trainer.state.best_metric or -1)\n",
        "\n",
        "log.info(\"🏁  Test‑set metrics:\")\n",
        "print(trainer.evaluate(eval_dataset=test_ref))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 584,
          "referenced_widgets": [
            "f1c23a45faf540c1b64e6d6b50414069",
            "7ee6d20dfac3448bb08878b66ac549a2",
            "247f40186de54f4da7a6f67a6419888e",
            "85b531020fe3481da16e3c7ab6a3361e",
            "fbc311186ebb424ebe278f5655c12d94",
            "29878746180147899a5c7aaab687d3b1",
            "292d32db09e949be9c01e43cc9e6eef8",
            "6da0b38df6364e84983180fae9f0fa09",
            "38cfb69eeaf84cd39780a5f232087e20",
            "f8e0ceab96c44b328f9621ee4a0c2482",
            "bbeea462e5664dc7b40dcdc9c6bcdda6"
          ]
        },
        "id": "OCec7raq-h_-",
        "outputId": "09f7c611-ee33-4ac7-c99b-9af9d869fbbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2567 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f1c23a45faf540c1b64e6d6b50414069"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of AlbertForTokenClassification were not initialized from the model checkpoint at ai4bharat/indic-bert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-7-cc99a0954ec2>:192: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1205' max='1205' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1205/1205 02:59, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Loc</th>\n",
              "      <th>Org</th>\n",
              "      <th>Per</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.390798</td>\n",
              "      <td>{'precision': 0.9141859544292862, 'recall': 0.9885563037639641, 'f1': 0.9499177139437462, 'number': 25691}</td>\n",
              "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 523}</td>\n",
              "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 704}</td>\n",
              "      <td>0.914186</td>\n",
              "      <td>0.943495</td>\n",
              "      <td>0.928609</td>\n",
              "      <td>0.917318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.320645</td>\n",
              "      <td>{'precision': 0.9175696312995418, 'recall': 0.9822505935930871, 'f1': 0.9488090538228714, 'number': 25691}</td>\n",
              "      <td>{'precision': 0.23076923076923078, 'recall': 0.0057361376673040155, 'f1': 0.011194029850746268, 'number': 523}</td>\n",
              "      <td>{'precision': 0.9090909090909091, 'recall': 0.014204545454545454, 'f1': 0.027972027972027972, 'number': 704}</td>\n",
              "      <td>0.917242</td>\n",
              "      <td>0.937960</td>\n",
              "      <td>0.927485</td>\n",
              "      <td>0.919045</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.544400</td>\n",
              "      <td>0.267844</td>\n",
              "      <td>{'precision': 0.9242165034761403, 'recall': 0.9883227589428204, 'f1': 0.9551952449025657, 'number': 25691}</td>\n",
              "      <td>{'precision': 0.48, 'recall': 0.045889101338432124, 'f1': 0.08376963350785341, 'number': 523}</td>\n",
              "      <td>{'precision': 0.8434782608695652, 'recall': 0.1377840909090909, 'f1': 0.23687423687423687, 'number': 704}</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.947767</td>\n",
              "      <td>0.935259</td>\n",
              "      <td>0.926245</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.544400</td>\n",
              "      <td>0.249893</td>\n",
              "      <td>{'precision': 0.951655881233346, 'recall': 0.9731034214316298, 'f1': 0.9622601566559535, 'number': 25691}</td>\n",
              "      <td>{'precision': 0.4293193717277487, 'recall': 0.3135755258126195, 'f1': 0.36243093922651937, 'number': 523}</td>\n",
              "      <td>{'precision': 0.5741029641185648, 'recall': 0.5227272727272727, 'f1': 0.5472118959107807, 'number': 704}</td>\n",
              "      <td>0.935478</td>\n",
              "      <td>0.948510</td>\n",
              "      <td>0.941949</td>\n",
              "      <td>0.933228</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.236200</td>\n",
              "      <td>0.245809</td>\n",
              "      <td>{'precision': 0.9505841430677908, 'recall': 0.9786306488653614, 'f1': 0.9644035289604909, 'number': 25691}</td>\n",
              "      <td>{'precision': 0.5506756756756757, 'recall': 0.31166347992351817, 'f1': 0.398046398046398, 'number': 523}</td>\n",
              "      <td>{'precision': 0.5968503937007874, 'recall': 0.5383522727272727, 'f1': 0.5660941000746826, 'number': 704}</td>\n",
              "      <td>0.938057</td>\n",
              "      <td>0.954157</td>\n",
              "      <td>0.946039</td>\n",
              "      <td>0.937907</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2/2 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.24383287131786346, 'eval_LOC': {'precision': 0.9393346379647749, 'recall': 0.96579476861167, 'f1': 0.9523809523809522, 'number': 497}, 'eval_ORG': {'precision': 0.16666666666666666, 'recall': 0.1111111111111111, 'f1': 0.13333333333333333, 'number': 9}, 'eval_PER': {'precision': 0.3333333333333333, 'recall': 0.2727272727272727, 'f1': 0.3, 'number': 11}, 'eval_precision': 0.9201520912547528, 'eval_recall': 0.9361702127659575, 'eval_f1': 0.9280920421860019, 'eval_accuracy': 0.9291044776119403, 'eval_runtime': 0.0887, 'eval_samples_per_second': 574.886, 'eval_steps_per_second': 22.545, 'epoch': 5.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###############################################################################\n",
        "# Indic-NER fine-tuning on Naamapadam (+ optional custom JSON)\n",
        "# with hyperparameter tuning\n",
        "###############################################################################\n",
        "import argparse, random, json, os, itertools, logging, collections\n",
        "import numpy as np, torch\n",
        "from datasets import load_dataset, concatenate_datasets, DatasetDict, Sequence, Value\n",
        "import evaluate\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForTokenClassification,\n",
        "    DataCollatorForTokenClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        ")\n",
        "\n",
        "# ──────────────────────────────────────────────────────────────\n",
        "# 0.  LOGGING\n",
        "# ──────────────────────────────────────────────────────────────\n",
        "logging.basicConfig(\n",
        "    format=\"%(asctime)s %(levelname)-8s %(message)s\",\n",
        "    level=logging.INFO,\n",
        "    datefmt=\"%H:%M:%S\",\n",
        ")\n",
        "log = logging.getLogger(__name__)\n",
        "\n",
        "# ──────────────────────────────────────────────────────────────\n",
        "# 1.  ARGUMENTS & SEEDING\n",
        "# ──────────────────────────────────────────────────────────────\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--model_name\", type=str, default=\"ai4bharat/indic-bert\")\n",
        "parser.add_argument(\"--languages\", nargs=\"+\", default=[\"as\"])\n",
        "parser.add_argument(\"--custom_data_path\", type=str, default=\"/content/drive/MyDrive/Yash_final_btp/naamapadam_proj/0.6/0.4/naamapadam_assamese.json\",\n",
        "                    help=\"Path to your extra JSON file (optional)\")\n",
        "parser.add_argument(\"--output_dir\", type=str,\n",
        "                    default=\"./indicner-finetuned-naamapadam\")\n",
        "parser.add_argument(\"--num_train_epochs\", type=int, default=10)\n",
        "parser.add_argument(\"--per_device_train_batch_size\", type=int, default=32)\n",
        "parser.add_argument(\"--per_device_eval_batch_size\", type=int, default=32)\n",
        "parser.add_argument(\"--learning_rate\", type=float, default=1e-5)\n",
        "parser.add_argument(\"--weight_decay\",  type=float, default=0.01)\n",
        "parser.add_argument(\"--warmup_steps\",  type=int, default=500)\n",
        "parser.add_argument(\"--seed\", type=int, default=42)\n",
        "args, _ = parser.parse_known_args()\n",
        "\n",
        "np.random.seed(args.seed)\n",
        "random.seed(args.seed)\n",
        "torch.manual_seed(args.seed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(args.seed)\n",
        "    log.info(\"CUDA device: %s\", torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    log.info(\"CUDA not available – falling back to CPU\")\n",
        "\n",
        "lang = args.languages[0]\n",
        "\n",
        "# ──────────────────────────────────────────────────────────────\n",
        "# 2.  CANONICAL LABEL SET  (Naamapadam has exactly 7)\n",
        "# ──────────────────────────────────────────────────────────────\n",
        "label_list = [\"B-LOC\",\"B-ORG\",\"B-PER\",\"I-LOC\",\"I-ORG\",\"I-PER\",\"O\"]\n",
        "id2label   = {i:l for i,l in enumerate(label_list)}  # type: ignore\n",
        "label2id   = {l:i for i,l in id2label.items()}\n",
        "num_labels = len(label_list)\n",
        "log.info(\"Canonical labels: %s\", id2label)\n",
        "\n",
        "# Helper – map *any* tag outside this list to “O”\n",
        "def normalise_tag(tag: str) -> str:\n",
        "    tag = str(tag)\n",
        "    if tag in (\"B-PERSON\", \"I-PERSON\"):         # your PERSON alias\n",
        "        tag = tag.replace(\"PERSON\", \"PER\")\n",
        "    return tag if tag in label2id else \"O\"\n",
        "\n",
        "# ──────────────────────────────────────────────────────────────\n",
        "# 3.  LOAD NAAMAPADAM (train / test)\n",
        "# ──────────────────────────────────────────────────────────────\n",
        "train_ref = load_dataset(\"ai4bharat/naamapadam\", lang, split=\"train\")\n",
        "test_ref  = load_dataset(\"ai4bharat/naamapadam\", lang, split=\"test\")\n",
        "\n",
        "# NEW  ➜  make their `ner_tags` column a plain int sequence\n",
        "int_seq = Sequence(Value(\"int64\"))\n",
        "train_ref = train_ref.cast_column(\"ner_tags\", int_seq)\n",
        "test_ref  = test_ref.cast_column(\"ner_tags\", int_seq)\n",
        "\n",
        "# ──────────────────────────────────────────────────────────────\n",
        "# 4.  OPTIONAL: LOAD + CLEAN YOUR CUSTOM JSON\n",
        "# ──────────────────────────────────────────────────────────────\n",
        "if args.custom_data_path:\n",
        "    log.info(\"Loading custom JSON: %s\", args.custom_data_path)\n",
        "    custom = load_dataset(\"json\", data_files=args.custom_data_path,\n",
        "                          split=\"train\")\n",
        "\n",
        "    # (a) ensure tokens / ner_tags length match\n",
        "    broken = [i for i, ex in enumerate(custom)\n",
        "              if len(ex[\"tokens\"]) != len(ex[\"ner_tags\"])]\n",
        "    if broken:\n",
        "        log.warning(\"⚠️  %d rows have mismatching lengths – they’ll be dropped\",\n",
        "                    len(broken))\n",
        "        custom = custom.select([i for i in range(len(custom)) if i not in broken])\n",
        "\n",
        "    # (b) normalise & map to ints\n",
        "    def _clean(batch):\n",
        "        out = []\n",
        "        for tags in batch[\"ner_tags\"]:\n",
        "            out.append([label2id[normalise_tag(t)] for t in tags])\n",
        "        batch[\"ner_tags\"] = out\n",
        "        return batch\n",
        "\n",
        "    custom = custom.map(_clean, batched=True)\n",
        "    log.info(\"Custom set after cleaning: %d sentences\", len(custom))\n",
        "    train_all = concatenate_datasets([train_ref, custom])\n",
        "else:\n",
        "    train_all = train_ref\n",
        "\n",
        "# quick label-distribution print-out\n",
        "def label_hist(ds, name):\n",
        "    flat = list(itertools.chain.from_iterable(ds[\"ner_tags\"]))\n",
        "    c = collections.Counter(flat)\n",
        "    log.info(\"%s label distribution: %s\",\n",
        "             name, {id2label[k]: v for k,v in c.items()})\n",
        "label_hist(train_all, \"TRAIN\")\n",
        "label_hist(test_ref,  \"TEST \")\n",
        "\n",
        "# ──────────────────────────────────────────────────────────────\n",
        "# 5. TRAIN / DEV SPLIT\n",
        "# ──────────────────────────────────────────────────────────────\n",
        "split = train_all.train_test_split(train_size=0.75, seed=args.seed)\n",
        "train_ds, dev_ds = split[\"train\"], split[\"test\"]\n",
        "log.info(\"Train %d  |  Dev %d  |  Test %d\",\n",
        "         len(train_ds), len(dev_ds), len(test_ref))\n",
        "\n",
        "# ──────────────────────────────────────────────────────────────\n",
        "# 6. TOKENISATION + LABEL ALIGNMENT\n",
        "# ──────────────────────────────────────────────────────────────\n",
        "tok = AutoTokenizer.from_pretrained(args.model_name, use_fast=True)\n",
        "def align(batch):\n",
        "    enc = tok(batch[\"tokens\"], is_split_into_words=True,\n",
        "              truncation=True, max_length=512)\n",
        "    new_labels = []\n",
        "    for i, seq in enumerate(batch[\"ner_tags\"]):\n",
        "        word_ids = enc.word_ids(batch_index=i)\n",
        "        prev = None\n",
        "        aligned = []\n",
        "        for w in word_ids:\n",
        "            if w is None:\n",
        "                aligned.append(-100)\n",
        "            elif w != prev:\n",
        "                aligned.append(seq[w])\n",
        "            else:\n",
        "                aligned.append(-100)\n",
        "            prev = w\n",
        "        new_labels.append(aligned)\n",
        "    enc[\"labels\"] = new_labels\n",
        "    return enc\n",
        "\n",
        "train_ds = train_ds.map(align, batched=True, remove_columns=[\"ner_tags\"])\n",
        "dev_ds   = dev_ds  .map(align, batched=True, remove_columns=[\"ner_tags\"])\n",
        "test_ref = test_ref.map(align, batched=True, remove_columns=[\"ner_tags\"])\n",
        "\n",
        "# ──────────────────────────────────────────────────────────────\n",
        "# 7. MODEL, METRICS, TRAINER\n",
        "# ──────────────────────────────────────────────────────────────\n",
        "metric = evaluate.load(\"seqeval\")\n",
        "def compute_metrics(p):\n",
        "    preds, labs = p\n",
        "    preds = np.argmax(preds, axis=2)\n",
        "    true_preds, true_labs = [], []\n",
        "    for pr, lb in zip(preds, labs):\n",
        "        pr_l, lb_l = [], []\n",
        "        for p_i, l_i in zip(pr, lb):\n",
        "            if l_i != -100:\n",
        "                pr_l.append(id2label[p_i])\n",
        "                lb_l.append(id2label[l_i])\n",
        "        true_preds.append(pr_l)\n",
        "        true_labs.append(lb_l)\n",
        "    res = metric.compute(predictions=true_preds, references=true_labs,\n",
        "                         zero_division=0)\n",
        "    return {k.replace(\"overall_\", \"\"): v for k,v in res.items()}\n",
        "\n",
        "def model_init():\n",
        "    return AutoModelForTokenClassification.from_pretrained(\n",
        "        args.model_name,\n",
        "        num_labels=num_labels,\n",
        "        id2label=id2label,\n",
        "        label2id=label2id\n",
        "    )\n",
        "\n",
        "train_args = TrainingArguments(\n",
        "    output_dir     = args.output_dir,\n",
        "    eval_strategy  =\"epoch\",\n",
        "    save_strategy  =\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",\n",
        "    num_train_epochs=args.num_train_epochs,\n",
        "    per_device_train_batch_size=args.per_device_train_batch_size,\n",
        "    per_device_eval_batch_size=args.per_device_eval_batch_size,\n",
        "    learning_rate = args.learning_rate,\n",
        "    weight_decay  = args.weight_decay,\n",
        "    warmup_steps  = args.warmup_steps,\n",
        "    seed = args.seed,\n",
        "    fp16 = torch.cuda.is_available(),\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model_init=model_init,\n",
        "    args=train_args,\n",
        "    train_dataset=train_ds,\n",
        "    eval_dataset=dev_ds,\n",
        "    tokenizer=tok,\n",
        "    data_collator=DataCollatorForTokenClassification(tok),\n",
        "    compute_metrics=compute_metrics)\n",
        "\n",
        "# ──────────────────────────────────────────────────────────────\n",
        "# 7b.  OPTIONAL: HYPERPARAMETER TUNING (Optuna)\n",
        "# ──────────────────────────────────────────────────────────────\n",
        "best_run = trainer.hyperparameter_search(\n",
        "    direction=\"maximize\",\n",
        "    backend=\"optuna\",\n",
        "    n_trials=10,\n",
        "    hp_space=lambda _: {\n",
        "        \"learning_rate\": np.random.uniform(1e-6, 1e-4),\n",
        "        \"per_device_train_batch_size\": np.random.choice([16, 32]),\n",
        "        \"weight_decay\": np.random.uniform(0.0, 0.3),\n",
        "    },\n",
        "    compute_objective=lambda metrics: metrics[\"eval_f1\"],\n",
        ")\n",
        "log.info(\"Best hyperparameters found: %s\", best_run)\n",
        "\n",
        "# ──────────────────────────────────────────────────────────────\n",
        "# 8. TRAIN & FINAL EVALUATION\n",
        "# ──────────────────────────────────────────────────────────────\n",
        "log.info(\"⏳  Starting fine-tuning …\")\n",
        "trainer.train()\n",
        "log.info(\"✅  Finished training.  Best dev-set F1: %.4f\",\n",
        "         trainer.state.best_metric or -1)\n",
        "\n",
        "log.info(\"🏁  Test-set metrics:\")\n",
        "print(trainer.evaluate(eval_dataset=test_ref))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "80534b4cbfe24e22bed966dbed1aa534",
            "ad1c9e185dc14d639be48d2de1f9d9cd",
            "bc344373044a44759fadb5c082daed6a",
            "9145411e42654092925bfb1148558b00",
            "3b1486c911554c16ba9d493533fd9c86",
            "e98bdc12e08349e893a979d0cb3ab0e6",
            "7437255934394224a157f665884eae72",
            "4f13e42294394ecb8cfb38e86b3666d1",
            "d3a5d57d60044af1b8c1db495d4f3b19",
            "602e5c5d2c044b7592f5e59262f180b3",
            "170bf2be37fe45c9b6f85efd46fcd50b",
            "6e65799441334cd9b5af6929e5dc5c2f",
            "65082176e78e4d9a80dc1d98d193f408",
            "4a44a7f9b59648e0a34428f4d0f85657",
            "dd17509912ae4729a6aea46540ce3481",
            "9762fe330cc0427b947089a58cecbfe6",
            "e389e100a3424f178caf5bc1f21b2c98",
            "00c4228e27794ac7909cb7d956196a84",
            "1de536d5d7824cdfbea4b3ad77096c15",
            "07638e87706144678d56cbb535b50145",
            "a97edc6f7d9843c0abbae870564b57e6",
            "82658fd77b1d455093c6966a9bfc03e6",
            "fd4e6f926d9e4de38418d69348ed6bfd",
            "929c51317c054c2787c10d264300ebe6",
            "0825236d679947bbbef1b7ece4b58f57",
            "57155956bf0244608371b7b94fa5dc80",
            "211316845de94d8c9863559e4a0ca7a4",
            "bdb42b1becc64f8796cac08a63ca3f8b",
            "a33e32e38205442d9b0ffae5f4a1a6aa",
            "a7f02a6816f94ab5872669e2158c007f",
            "46070d206fc64b44a87bc4836d3bb4b9",
            "e8822b216e4d476c98f8038b5f1e3ac0",
            "1e44f5f31bdb4c47b92b5149985665ed",
            "a1521f1ee6c74abdab30f11ac37658d9",
            "e4abf5550e7f42b28753decc3d389886",
            "55f0388f66944fd3ad01e5ab95d98fd1",
            "05cb079570aa4874b935278235b6fdba",
            "23f59574b19a4c88978aeb9cf94d1379",
            "088e9841e7d3472fa7f1fc1be4de43f2",
            "f7e5dc2b15a5471b954ee3516c09c772",
            "222a717ee36e49d38a40e3d4ca897e57",
            "ff7eb68446bc45d9b52fbb2991a1c1d4",
            "1c2c44a38ff44c5a9fca843d3af34301",
            "91796f00ce8947ff98f22f38c53f8e3e",
            "7d063541a79048748bb8c98d60a73f4c",
            "95fcb5dc354647a7bf545e4e2d21e335",
            "be6ea86fdf4e4153ab7a2e4743230187",
            "8f7dc6d2dbf84a8c8533395b6e3b7584",
            "ff760b6327734aae881ce62c63ca6497",
            "e9915f4faf2449f58e1520823a6c9866",
            "52ca76c24ed943dc8b083dcc01c0e65a",
            "75fa1f508e5a4bec913b445b292f4f5c",
            "82b63127b8cc44e1a7f992b81113d08c",
            "cf5910f0cb0c4c58b166b3e18d14a479",
            "12a45a59e06f48e8b315df747a7a5dbc",
            "d66369b9291e48c6ace4dbd07df05ac8",
            "9db7d9e5a8814440b7c2b1e62bb92c11",
            "b1fca248510a448aa1add83ec270f949",
            "5a89ba3b0c164785a9e881293859ca8c",
            "6a85fa8c47284289ae906acba242fd75",
            "860649733db84b3f8c0dc4f1b4b9dd62",
            "f62d6236d2a84612a6a90e4d24266032",
            "2889715159af4ff8bf1c559c1301ba4b",
            "e5a376d385d6472d8efdee6656d44fd9",
            "4d2fc2d10b6a42ea9bdbff39d29cfd48",
            "a552aab170bc460196ff9ddb1d453355",
            "fad368e1e9a742c785b372374885240d",
            "79d62025473e4106bd0dddb6b635d314",
            "34cfe48b820e44419a578d5daddb0167",
            "b8d1c3162370498d83eb4cbd86b862e8",
            "c7576e9044a143899f887bd399fe4197",
            "87e5c2bfcc58469ba7a3c7af003e70cc",
            "0839fb97dc3c4bd98133ae3a3910ffa1",
            "f3bc6e1ca9584b5cbce905201cf03e23",
            "147555c86af243d9bdc09c2341eab5a9",
            "0002c055825047a88bc11af13ec59ed6",
            "f1660753475241668cd763086349a546",
            "297da51cde9f4357a70455ba85bb1280",
            "58441be423f144b0af91bbc24f9b936c",
            "a77cd6e95a0d48d2b3846dab95294463",
            "9ef3c8d8c6c44274aff356a9df087c8b",
            "8e1251e8162047a0a1e2baa66db469de",
            "dd93da2b188b4f658a9ba597e1bf7c09",
            "344b4c6e349643b38d4ebf9b31dda2f8",
            "c9e6c2fc83c649638c65615bd198a065",
            "c426a468491848c5a671e0ccaedd7290",
            "904fcb70b6c6475eb3da120abf8a5303",
            "ffbc0b20ea8841fda7e400ceefdf4ef5",
            "93dd3cf67d5a4ccaa14976ce0159f23c",
            "905a18fbfbcd46d18456c9c32d914782",
            "bccf410b53084d1cb1bbaea34011e65d",
            "cc17ad0463d84e19a7d2f2ff7174c242",
            "d33a3df1ddaa48ae992e1a55210a3630",
            "acf63897a56a471ab9e0538ba0aab06a",
            "e180aec168e940ffa78f1a719ad796af",
            "8d74bd9f732046519633a3d7aeae2f47",
            "aefe4e232b624cfd9292f807c59de41b",
            "b92bf71cafae4a79ae4c8b99f398adff",
            "14e0e714f7a44ce0a70b83032f6d5364",
            "c7bc8caa1ec8493db4d48e47fbb5c1e0",
            "3d601d51d6ae4a419155df79f95b7383",
            "519989e8a4f84302abab007933714415",
            "22ae03e67f164f809565eaab4b4dc1cb",
            "d83a300bcea8414ebe9e5ef556f16c53",
            "8cacde596f924384b152bebeeb702fb2",
            "cf7a42cce96a46a7a6a938eaffb52809",
            "04ce085b192542bd9749587b132d915a",
            "2b39e3165c654005bd1cbcfd74206d7a",
            "038060a3e8084a2eb52eb42eab044bf6",
            "cd4bff6c62b0446987b7240607ca6cf3",
            "0663e5432e2e42de8a6c4ca09750e209",
            "44ee5ae4dabc49df83e13846def3ee8b",
            "d0e67d7690dc4f6cab0be6edd39c5326",
            "17e1ba28f7d0435cb8a47b72d723b80b",
            "622800bdcc004ca2a3c64f060c878525",
            "940b61ceb02e42cd8c6e9027b1643757",
            "e46a3ceab4604ba68c515d55af7f6117",
            "d01807c3fae745ea8cbd601001b7426c",
            "0d7d067b30e24007b4416a20ef3f59b2",
            "e5ce0516d47740c295a9ee8b9369c005",
            "e3d3fb19089b4f23a6116aa7bdaa8cc6",
            "6c32c5b7509449219e8185fd2acf27da",
            "c0df04ec4e1e4d8fb0d3fd1ea707249f",
            "79524059e10a4950aba0afb495d4db18",
            "16778eacf93043a881303f1573eafc91",
            "88b58b00e00f49be81beb7b0173bd040",
            "6bcff92989ab448ca409290dbc6ad6e0",
            "adebccdbed8443068911af4f9e936f70",
            "1f0de1b58d604ca98010a99cf3f5dc3b",
            "aa918629655b412cb205a20ced51e249",
            "b735e9e6e9024213b2c4fc17bc108654",
            "6fcbba1fc8594b4da6fad9f694ba6bb4",
            "5720f36040cb406ba7ccdf20e20b5776",
            "b5853836a1c64336a8dcd0718ef6dbbf",
            "09f851d66a98477a9ce9291178ffc91c",
            "a176fae3c81b4eeca76318063edb0ea4",
            "cf1dfa9803de4ad4a5f43bf8248a3d8e",
            "151254d0516a4b9f99cc143eabc858fd",
            "36c279d2d03d4d2a947ef0b2fda95f0c",
            "f05f9a29be254eed910687ca8f3dd0d2",
            "c3f05e197d704695823fdf082dab9fc7",
            "1512e1bea5574248877135c7aca18d81",
            "0ea979e89c4149e2ab0e5faf7e4e8653",
            "4b57f8266fa64318bc6597ac30cf1333",
            "77088c5afe2c4e8582169652cee5f305",
            "f325edf764124f09ae74fd0f1d8eb351",
            "cd188d5de82f4d4f886fee380770d21e",
            "ea079038948d4cf7888a853f6a5270bb",
            "43ae789358d649598413bd177d00ff25",
            "7acfc6f4b53349d9923306612cbda040",
            "d90445cbb06c414ab8a48ad370cdd04e",
            "d6de27018bcd43d3993e5db0296d8553",
            "e294c4d5d4a24a338c22b98d3e5e11fa",
            "2c0e82e3a04e478e9bd2f77bf62fbbb1",
            "d63ba8d3ae974640bc593603e852bfeb",
            "976abe80ffeb4f22bcedcb1961980db7",
            "484124b37c794bc78e5debe67abff267",
            "7d462baa8021451497856b5efd0d64e4",
            "61fb0d530a534b70b2e67da0923c037c",
            "07dfe32e932849d289d7b6441ddce0d4",
            "8d1a0ea92a5d44c292eb4de194158e3a",
            "ddc736d4c3c64209a88665e1259225aa",
            "8f832e258ecc43b7adbe10d960b55dfe",
            "782aa460d3d94327b2ff3c37dfa73886",
            "873e35b0152c4c5a9720f67eee2d6ede",
            "ae9cb593df7b424d86dceeef34a6558b",
            "dc13c94cee5644dda807059be8389277",
            "498d197878dd411c814d2625846216ff",
            "c44f4484f7c44d3387ca787a3fc0fc8a",
            "1c1f4e5eaab4451ea453fc0db8efa1c1",
            "77b30eb9b4e54cc0a3a3680042ded98c",
            "ce9c392063e946fd85ac62273a661523",
            "90e6ff1724db408198a18dd4ff8a6b2c",
            "3a0bdf15c934469cb8f305a3b2e61a2f",
            "a0e582e3d2d74a658881f521f3892e93",
            "353076858f8e44b9bd5ea9b022a8fcfa",
            "7065690b23af4827b4573c9b46817bce",
            "9a1ada9c305d4a50972cc43c3c944b5e",
            "bd303cac38a84646834918749157c67c",
            "ebd8e0b5063443438355e55cd4ae21aa",
            "491756c25ce145fc91a00d1676555863",
            "6755a4ce1e3144a5bb3d8aa773a7cec4",
            "bbc091f53e564a21b0e59bb2541ce3de",
            "6b8d9bb51f794349abef371327e45fa1",
            "41995bf869af4d3c81f6d4e058e54a67",
            "e8390549a2b345bb8120c33236554db1",
            "0b6ca1ed39d84c32909c190e46697be3",
            "451445a0af8747ae8de6feb58ba7fd9c",
            "cab4418749dd4c8996a5274818227804",
            "f983c2e7fd304ea69ccc4528531965fb",
            "5f7a27eacf5545ab8be5b97b9471a4e3",
            "77f8eb0ef2ec400790c8b6bb5ba71448",
            "ee68f4eae0fc4745b613b8c1d653630a",
            "738631abe6c74dc081e9f05e19adcc53",
            "cfd372eece684785851e9d2ded19a22d",
            "34ec124bf4944abe88666605ddbb24fe",
            "a64223f375c845c79a04989f6bc272a9",
            "fd581d0b7490458a96e997fe0755c809",
            "f46c0e72784d4b3ba191a902239a6c6c",
            "a29714a8fc4a4ab882d6612e45fd4437",
            "9b9537e239d641179d0c3df90410af82",
            "1723b7bc9fb94efd8ac890330a1d2e42",
            "3a4e0a888f4d44d19d769c039d6a16f5",
            "fc7fc0c604664eb380e491872ead82dc",
            "904b2862b81248ce95e48fb99baba7b9",
            "41261b827fd74e5ab0f666f6258f0c8d",
            "63c2b498a0594071bead651ea5b416be",
            "1460bc17819944e1a6fd24855d26fb89",
            "7bc808b54fce40a4b7f82084065a1dc2",
            "b61716664038463893b549e9a30ebed6",
            "3ad39bb7e16547ec99f47321113acb27",
            "30ca2ff6e60e40d0aef393198b57c7cb",
            "5c4f8ca783f2477a83decd17d552c232",
            "82b9bcbd1fdf4519ae608e926243340e",
            "f00da13d039747c69d65c616cadd6ac2",
            "a910ac877d644d9a9e6c0b852e794580",
            "7d581b45f8594de0a9a2da4037731b9b",
            "6ae2d330aab4419685c2218a41c8d57a",
            "d9c19cbbc8664b4292cc29c93abff002",
            "e3d60f6ced32459ba426b2f0aa9664f3"
          ]
        },
        "id": "N_WWyQhSaGTP",
        "outputId": "2513797d-f55a-45ac-93b0-2e8f12e0c1d4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/8.65k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "80534b4cbfe24e22bed966dbed1aa534"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "naamapadam.py:   0%|          | 0.00/2.86k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6e65799441334cd9b5af6929e5dc5c2f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0000.parquet:   0%|          | 0.00/654k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fd4e6f926d9e4de38418d69348ed6bfd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0000.parquet:   0%|          | 0.00/6.77k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a1521f1ee6c74abdab30f11ac37658d9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0000.parquet:   0%|          | 0.00/7.29k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7d063541a79048748bb8c98d60a73f4c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/10266 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d66369b9291e48c6ace4dbd07df05ac8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/51 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fad368e1e9a742c785b372374885240d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/52 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "297da51cde9f4357a70455ba85bb1280"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Casting the dataset:   0%|          | 0/10266 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "93dd3cf67d5a4ccaa14976ce0159f23c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Casting the dataset:   0%|          | 0/51 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c7bc8caa1ec8493db4d48e47fbb5c1e0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0663e5432e2e42de8a6c4ca09750e209"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1437 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6c32c5b7509449219e8185fd2acf27da"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/507 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5720f36040cb406ba7ccdf20e20b5776"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/5.65M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4b57f8266fa64318bc6597ac30cf1333"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/8777 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d63ba8d3ae974640bc593603e852bfeb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2926 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ae9cb593df7b424d86dceeef34a6558b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/51 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7065690b23af4827b4573c9b46817bce"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/6.34k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "451445a0af8747ae8de6feb58ba7fd9c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-d56b52fab291>:204: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/135M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f46c0e72784d4b3ba191a902239a6c6c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of AlbertForTokenClassification were not initialized from the model checkpoint at ai4bharat/indic-bert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[I 2025-05-11 21:08:54,634] A new study created in memory with name: no-name-04a12f66-7021-4986-9be9-0a580320cafb\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/135M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b61716664038463893b549e9a30ebed6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of AlbertForTokenClassification were not initialized from the model checkpoint at ai4bharat/indic-bert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5490' max='5490' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5490/5490 06:51, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Loc</th>\n",
              "      <th>Org</th>\n",
              "      <th>Per</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.858400</td>\n",
              "      <td>0.607546</td>\n",
              "      <td>{'precision': 0.8004271015336828, 'recall': 0.9736686739874838, 'f1': 0.8785893133024346, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 773}</td>\n",
              "      <td>{'precision': 0.4, 'recall': 0.0018399264029438822, 'f1': 0.003663003663003663, 'number': 1087}</td>\n",
              "      <td>0.800362</td>\n",
              "      <td>0.907324</td>\n",
              "      <td>0.850493</td>\n",
              "      <td>0.802981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.529300</td>\n",
              "      <td>0.620513</td>\n",
              "      <td>{'precision': 0.8243934862080425, 'recall': 0.976345101743614, 'f1': 0.8939582319765033, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.2602739726027397, 'recall': 0.02457956015523933, 'f1': 0.04491725768321513, 'number': 773}</td>\n",
              "      <td>{'precision': 0.5106382978723404, 'recall': 0.22079116835326587, 'f1': 0.30828516377649323, 'number': 1087}</td>\n",
              "      <td>0.818235</td>\n",
              "      <td>0.919243</td>\n",
              "      <td>0.865803</td>\n",
              "      <td>0.824935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.411800</td>\n",
              "      <td>0.545496</td>\n",
              "      <td>{'precision': 0.9221589032044929, 'recall': 0.8789310032668163, 'f1': 0.9000261975293715, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.4909090909090909, 'recall': 0.10478654592496765, 'f1': 0.17270788912579957, 'number': 773}</td>\n",
              "      <td>{'precision': 0.643312101910828, 'recall': 0.27874885004599814, 'f1': 0.3889602053915276, 'number': 1087}</td>\n",
              "      <td>0.914011</td>\n",
              "      <td>0.833058</td>\n",
              "      <td>0.871659</td>\n",
              "      <td>0.836326</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.336900</td>\n",
              "      <td>0.507872</td>\n",
              "      <td>{'precision': 0.9019488660107131, 'recall': 0.9344668792065179, 'f1': 0.917919969070172, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.5714285714285714, 'recall': 0.12419146183699871, 'f1': 0.20403825717321997, 'number': 773}</td>\n",
              "      <td>{'precision': 0.7307692307692307, 'recall': 0.2621895124195032, 'f1': 0.38591740013540965, 'number': 1087}</td>\n",
              "      <td>0.897400</td>\n",
              "      <td>0.884696</td>\n",
              "      <td>0.891002</td>\n",
              "      <td>0.862449</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.255300</td>\n",
              "      <td>0.592992</td>\n",
              "      <td>{'precision': 0.8817279155827502, 'recall': 0.9471799110481364, 'f1': 0.9132827324478179, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.49557522123893805, 'recall': 0.1448900388098318, 'f1': 0.22422422422422417, 'number': 773}</td>\n",
              "      <td>{'precision': 0.7120181405895691, 'recall': 0.2888684452621895, 'f1': 0.4109947643979058, 'number': 1087}</td>\n",
              "      <td>0.875930</td>\n",
              "      <td>0.898192</td>\n",
              "      <td>0.886921</td>\n",
              "      <td>0.856254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.231900</td>\n",
              "      <td>0.535721</td>\n",
              "      <td>{'precision': 0.907690530288443, 'recall': 0.9276970913527768, 'f1': 0.9175847705064819, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.44274809160305345, 'recall': 0.22509702457956016, 'f1': 0.2984562607204117, 'number': 773}</td>\n",
              "      <td>{'precision': 0.5520094562647754, 'recall': 0.4296228150873965, 'f1': 0.4831867563372995, 'number': 1087}</td>\n",
              "      <td>0.889914</td>\n",
              "      <td>0.887923</td>\n",
              "      <td>0.888917</td>\n",
              "      <td>0.860536</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.182500</td>\n",
              "      <td>0.605040</td>\n",
              "      <td>{'precision': 0.9130552756027599, 'recall': 0.9271067028771598, 'f1': 0.9200273410799726, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.38362068965517243, 'recall': 0.23027166882276842, 'f1': 0.2877930476960388, 'number': 773}</td>\n",
              "      <td>{'precision': 0.545, 'recall': 0.40110395584176634, 'f1': 0.46210916799152096, 'number': 1087}</td>\n",
              "      <td>0.893097</td>\n",
              "      <td>0.886383</td>\n",
              "      <td>0.889727</td>\n",
              "      <td>0.860993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.157200</td>\n",
              "      <td>0.621727</td>\n",
              "      <td>{'precision': 0.9041461647022924, 'recall': 0.9329712284016216, 'f1': 0.9183325584999225, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.4168564920273349, 'recall': 0.23673997412677877, 'f1': 0.30198019801980197, 'number': 773}</td>\n",
              "      <td>{'precision': 0.5559400230680508, 'recall': 0.44342226310947563, 'f1': 0.49334698055271237, 'number': 1087}</td>\n",
              "      <td>0.885405</td>\n",
              "      <td>0.893718</td>\n",
              "      <td>0.889542</td>\n",
              "      <td>0.860194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.136700</td>\n",
              "      <td>0.645352</td>\n",
              "      <td>{'precision': 0.905265973708346, 'recall': 0.9323808399260046, 'f1': 0.9186233640329616, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.3831967213114754, 'recall': 0.24191461836998707, 'f1': 0.2965900079302141, 'number': 773}</td>\n",
              "      <td>{'precision': 0.5577395577395577, 'recall': 0.41766329346826125, 'f1': 0.47764334560757493, 'number': 1087}</td>\n",
              "      <td>0.885693</td>\n",
              "      <td>0.892287</td>\n",
              "      <td>0.888978</td>\n",
              "      <td>0.860650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.111000</td>\n",
              "      <td>0.658066</td>\n",
              "      <td>{'precision': 0.9052310042000764, 'recall': 0.9331286653284527, 'f1': 0.9189681570633952, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.3802521008403361, 'recall': 0.23415265200517466, 'f1': 0.2898318654923939, 'number': 773}</td>\n",
              "      <td>{'precision': 0.5405092592592593, 'recall': 0.4296228150873965, 'f1': 0.4787288569964121, 'number': 1087}</td>\n",
              "      <td>0.884708</td>\n",
              "      <td>0.893241</td>\n",
              "      <td>0.888954</td>\n",
              "      <td>0.860393</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-11 21:15:49,657] Trial 0 finished with value: 0.8889537748416884 and parameters: {}. Best is trial 0 with value: 0.8889537748416884.\n",
            "Some weights of AlbertForTokenClassification were not initialized from the model checkpoint at ai4bharat/indic-bert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5490' max='5490' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5490/5490 06:57, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Loc</th>\n",
              "      <th>Org</th>\n",
              "      <th>Per</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.858400</td>\n",
              "      <td>0.607546</td>\n",
              "      <td>{'precision': 0.8004271015336828, 'recall': 0.9736686739874838, 'f1': 0.8785893133024346, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 773}</td>\n",
              "      <td>{'precision': 0.4, 'recall': 0.0018399264029438822, 'f1': 0.003663003663003663, 'number': 1087}</td>\n",
              "      <td>0.800362</td>\n",
              "      <td>0.907324</td>\n",
              "      <td>0.850493</td>\n",
              "      <td>0.802981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.530800</td>\n",
              "      <td>0.602813</td>\n",
              "      <td>{'precision': 0.8299979921022689, 'recall': 0.9761876648167828, 'f1': 0.8971766535838954, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.17647058823529413, 'recall': 0.015523932729624839, 'f1': 0.028537455410225922, 'number': 773}</td>\n",
              "      <td>{'precision': 0.5186104218362283, 'recall': 0.1922723091076357, 'f1': 0.28053691275167786, 'number': 1087}</td>\n",
              "      <td>0.824400</td>\n",
              "      <td>0.917703</td>\n",
              "      <td>0.868553</td>\n",
              "      <td>0.830331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.421000</td>\n",
              "      <td>0.500999</td>\n",
              "      <td>{'precision': 0.9201368174044465, 'recall': 0.910575825559885, 'f1': 0.9153313550939663, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.38309859154929576, 'recall': 0.1759379042690815, 'f1': 0.24113475177304963, 'number': 773}</td>\n",
              "      <td>{'precision': 0.6196660482374768, 'recall': 0.30726770929162833, 'f1': 0.4108241082410824, 'number': 1087}</td>\n",
              "      <td>0.906594</td>\n",
              "      <td>0.865698</td>\n",
              "      <td>0.885675</td>\n",
              "      <td>0.856825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.339900</td>\n",
              "      <td>0.517468</td>\n",
              "      <td>{'precision': 0.9159710190581194, 'recall': 0.9155744479867753, 'f1': 0.9157726905891385, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.6722689075630253, 'recall': 0.1034928848641656, 'f1': 0.17937219730941703, 'number': 773}</td>\n",
              "      <td>{'precision': 0.7186700767263428, 'recall': 0.25850965961361544, 'f1': 0.38024357239512857, 'number': 1087}</td>\n",
              "      <td>0.911874</td>\n",
              "      <td>0.866359</td>\n",
              "      <td>0.888534</td>\n",
              "      <td>0.857538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.262300</td>\n",
              "      <td>0.554863</td>\n",
              "      <td>{'precision': 0.8941010296249489, 'recall': 0.9467469594993506, 'f1': 0.9196711909768687, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.43729903536977494, 'recall': 0.1759379042690815, 'f1': 0.2509225092250923, 'number': 773}</td>\n",
              "      <td>{'precision': 0.6290050590219224, 'recall': 0.34314627414903404, 'f1': 0.444047619047619, 'number': 1087}</td>\n",
              "      <td>0.883339</td>\n",
              "      <td>0.900833</td>\n",
              "      <td>0.892000</td>\n",
              "      <td>0.862877</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.226900</td>\n",
              "      <td>0.538479</td>\n",
              "      <td>{'precision': 0.9098646628071925, 'recall': 0.9340732868894399, 'f1': 0.9218100602058652, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.4787234042553192, 'recall': 0.23285899094437257, 'f1': 0.3133159268929504, 'number': 773}</td>\n",
              "      <td>{'precision': 0.6391304347826087, 'recall': 0.40570377184912604, 'f1': 0.4963421496904897, 'number': 1087}</td>\n",
              "      <td>0.897013</td>\n",
              "      <td>0.893131</td>\n",
              "      <td>0.895068</td>\n",
              "      <td>0.867245</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.189900</td>\n",
              "      <td>0.571037</td>\n",
              "      <td>{'precision': 0.9049422457867828, 'recall': 0.9404888416578109, 'f1': 0.9223731953987493, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.43703703703703706, 'recall': 0.22897800776196636, 'f1': 0.300509337860781, 'number': 773}</td>\n",
              "      <td>{'precision': 0.5347222222222222, 'recall': 0.4250229990800368, 'f1': 0.47360328036904153, 'number': 1087}</td>\n",
              "      <td>0.886536</td>\n",
              "      <td>0.899769</td>\n",
              "      <td>0.893104</td>\n",
              "      <td>0.863734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.166300</td>\n",
              "      <td>0.597636</td>\n",
              "      <td>{'precision': 0.9011488211443159, 'recall': 0.944739638682253, 'f1': 0.9224295294275888, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.45036319612590797, 'recall': 0.240620957309185, 'f1': 0.3136593591905565, 'number': 773}</td>\n",
              "      <td>{'precision': 0.5531674208144797, 'recall': 0.44986200551977923, 'f1': 0.4961948249619483, 'number': 1087}</td>\n",
              "      <td>0.883471</td>\n",
              "      <td>0.905050</td>\n",
              "      <td>0.894130</td>\n",
              "      <td>0.866360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.139800</td>\n",
              "      <td>0.618357</td>\n",
              "      <td>{'precision': 0.9162882757014786, 'recall': 0.9292714606210887, 'f1': 0.9227342009614258, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.39920948616600793, 'recall': 0.2613195342820181, 'f1': 0.3158717748240813, 'number': 773}</td>\n",
              "      <td>{'precision': 0.5638051044083526, 'recall': 0.44710211591536336, 'f1': 0.4987172909184197, 'number': 1087}</td>\n",
              "      <td>0.895449</td>\n",
              "      <td>0.891114</td>\n",
              "      <td>0.893276</td>\n",
              "      <td>0.864704</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.117300</td>\n",
              "      <td>0.620726</td>\n",
              "      <td>{'precision': 0.9135525756463269, 'recall': 0.9304522375723225, 'f1': 0.9219249668512597, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.3992248062015504, 'recall': 0.2664941785252264, 'f1': 0.31962761830876646, 'number': 773}</td>\n",
              "      <td>{'precision': 0.54627539503386, 'recall': 0.4452621895124195, 'f1': 0.4906234161175875, 'number': 1087}</td>\n",
              "      <td>0.891895</td>\n",
              "      <td>0.892287</td>\n",
              "      <td>0.892091</td>\n",
              "      <td>0.864048</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-11 21:22:48,832] Trial 1 finished with value: 0.892091079089209 and parameters: {}. Best is trial 1 with value: 0.892091079089209.\n",
            "Some weights of AlbertForTokenClassification were not initialized from the model checkpoint at ai4bharat/indic-bert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5490' max='5490' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5490/5490 07:05, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Loc</th>\n",
              "      <th>Org</th>\n",
              "      <th>Per</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.858400</td>\n",
              "      <td>0.607546</td>\n",
              "      <td>{'precision': 0.8004271015336828, 'recall': 0.9736686739874838, 'f1': 0.8785893133024346, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 773}</td>\n",
              "      <td>{'precision': 0.4, 'recall': 0.0018399264029438822, 'f1': 0.003663003663003663, 'number': 1087}</td>\n",
              "      <td>0.800362</td>\n",
              "      <td>0.907324</td>\n",
              "      <td>0.850493</td>\n",
              "      <td>0.802981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.530800</td>\n",
              "      <td>0.612300</td>\n",
              "      <td>{'precision': 0.8232627399073461, 'recall': 0.9792183256582832, 'f1': 0.8944936811260719, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.19444444444444445, 'recall': 0.018111254851228976, 'f1': 0.033136094674556214, 'number': 773}</td>\n",
              "      <td>{'precision': 0.4864864864864865, 'recall': 0.19871205151793928, 'f1': 0.28216851730894843, 'number': 1087}</td>\n",
              "      <td>0.816925</td>\n",
              "      <td>0.920857</td>\n",
              "      <td>0.865783</td>\n",
              "      <td>0.825192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.419700</td>\n",
              "      <td>0.498722</td>\n",
              "      <td>{'precision': 0.9169577962494478, 'recall': 0.898768056047546, 'f1': 0.9077718147485588, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.5207373271889401, 'recall': 0.1461836998706339, 'f1': 0.22828282828282828, 'number': 773}</td>\n",
              "      <td>{'precision': 0.6449814126394052, 'recall': 0.31922723091076355, 'f1': 0.4270769230769231, 'number': 1087}</td>\n",
              "      <td>0.907904</td>\n",
              "      <td>0.854329</td>\n",
              "      <td>0.880302</td>\n",
              "      <td>0.848203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.333100</td>\n",
              "      <td>0.542443</td>\n",
              "      <td>{'precision': 0.9129146688496472, 'recall': 0.9217538473648994, 'f1': 0.9173129651390521, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.5806451612903226, 'recall': 0.11642949547218628, 'f1': 0.1939655172413793, 'number': 773}</td>\n",
              "      <td>{'precision': 0.6599496221662469, 'recall': 0.24103035878564857, 'f1': 0.353099730458221, 'number': 1087}</td>\n",
              "      <td>0.907117</td>\n",
              "      <td>0.871786</td>\n",
              "      <td>0.889101</td>\n",
              "      <td>0.858224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.249700</td>\n",
              "      <td>0.521162</td>\n",
              "      <td>{'precision': 0.9085556999770624, 'recall': 0.935411500767505, 'f1': 0.9217880345195385, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.5247148288973384, 'recall': 0.17852522639068563, 'f1': 0.26640926640926643, 'number': 773}</td>\n",
              "      <td>{'precision': 0.6339144215530903, 'recall': 0.36798528058877644, 'f1': 0.46565774155995343, 'number': 1087}</td>\n",
              "      <td>0.898418</td>\n",
              "      <td>0.891334</td>\n",
              "      <td>0.894862</td>\n",
              "      <td>0.865104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.225100</td>\n",
              "      <td>0.535770</td>\n",
              "      <td>{'precision': 0.9020892616444511, 'recall': 0.9482819695359547, 'f1': 0.9246090377050753, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.48286604361370716, 'recall': 0.20051746442432083, 'f1': 0.283363802559415, 'number': 773}</td>\n",
              "      <td>{'precision': 0.6218487394957983, 'recall': 0.40846366145354185, 'f1': 0.49305941143808985, 'number': 1087}</td>\n",
              "      <td>0.890026</td>\n",
              "      <td>0.905564</td>\n",
              "      <td>0.897728</td>\n",
              "      <td>0.870471</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.177100</td>\n",
              "      <td>0.589372</td>\n",
              "      <td>{'precision': 0.9082924603627238, 'recall': 0.9402526862675641, 'f1': 0.9239962868414945, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.4379746835443038, 'recall': 0.2238033635187581, 'f1': 0.2962328767123288, 'number': 773}</td>\n",
              "      <td>{'precision': 0.5615577889447236, 'recall': 0.41122355105795766, 'f1': 0.47477429633563467, 'number': 1087}</td>\n",
              "      <td>0.891496</td>\n",
              "      <td>0.898852</td>\n",
              "      <td>0.895159</td>\n",
              "      <td>0.868159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.160400</td>\n",
              "      <td>0.599863</td>\n",
              "      <td>{'precision': 0.9032233826733789, 'recall': 0.946274648718857, 'f1': 0.9242479577126381, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.4288990825688073, 'recall': 0.24191461836998707, 'f1': 0.3093465674110835, 'number': 773}</td>\n",
              "      <td>{'precision': 0.5721212121212121, 'recall': 0.43422263109475623, 'f1': 0.493723849372385, 'number': 1087}</td>\n",
              "      <td>0.886007</td>\n",
              "      <td>0.905894</td>\n",
              "      <td>0.895840</td>\n",
              "      <td>0.869472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.136600</td>\n",
              "      <td>0.622366</td>\n",
              "      <td>{'precision': 0.9064930162325405, 'recall': 0.9451332309993309, 'f1': 0.9254099466250457, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.4481132075471698, 'recall': 0.24579560155239327, 'f1': 0.3174603174603175, 'number': 773}</td>\n",
              "      <td>{'precision': 0.5725094577553594, 'recall': 0.41766329346826125, 'f1': 0.4829787234042553, 'number': 1087}</td>\n",
              "      <td>0.889920</td>\n",
              "      <td>0.904280</td>\n",
              "      <td>0.897042</td>\n",
              "      <td>0.870614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.112100</td>\n",
              "      <td>0.634707</td>\n",
              "      <td>{'precision': 0.9084552536576097, 'recall': 0.9409217932065966, 'f1': 0.92440354201307, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.38747553816046965, 'recall': 0.25614489003880986, 'f1': 0.30841121495327106, 'number': 773}</td>\n",
              "      <td>{'precision': 0.5502283105022832, 'recall': 0.44342226310947563, 'f1': 0.4910850738665309, 'number': 1087}</td>\n",
              "      <td>0.887517</td>\n",
              "      <td>0.901676</td>\n",
              "      <td>0.894541</td>\n",
              "      <td>0.868444</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-11 21:29:55,821] Trial 2 finished with value: 0.8945405592242901 and parameters: {}. Best is trial 2 with value: 0.8945405592242901.\n",
            "Some weights of AlbertForTokenClassification were not initialized from the model checkpoint at ai4bharat/indic-bert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5490' max='5490' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5490/5490 06:59, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Loc</th>\n",
              "      <th>Org</th>\n",
              "      <th>Per</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.855500</td>\n",
              "      <td>0.568183</td>\n",
              "      <td>{'precision': 0.8299979579334287, 'recall': 0.959853583658047, 'f1': 0.8902151891803098, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 773}</td>\n",
              "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1087}</td>\n",
              "      <td>0.829998</td>\n",
              "      <td>0.894378</td>\n",
              "      <td>0.860986</td>\n",
              "      <td>0.822822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.529200</td>\n",
              "      <td>0.598683</td>\n",
              "      <td>{'precision': 0.8249176180807509, 'recall': 0.9754398394143347, 'f1': 0.8938863841298468, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.1282051282051282, 'recall': 0.00646830530401035, 'f1': 0.012315270935960592, 'number': 773}</td>\n",
              "      <td>{'precision': 0.3988919667590028, 'recall': 0.26494940202391903, 'f1': 0.3184079601990049, 'number': 1087}</td>\n",
              "      <td>0.814050</td>\n",
              "      <td>0.919646</td>\n",
              "      <td>0.863632</td>\n",
              "      <td>0.822166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.412000</td>\n",
              "      <td>0.490568</td>\n",
              "      <td>{'precision': 0.9194041867954912, 'recall': 0.8988861337426693, 'f1': 0.9090293947897387, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.4797687861271676, 'recall': 0.1073738680465718, 'f1': 0.17547568710359407, 'number': 773}</td>\n",
              "      <td>{'precision': 0.7777777777777778, 'recall': 0.22539098436062557, 'f1': 0.3495007132667618, 'number': 1087}</td>\n",
              "      <td>0.914640</td>\n",
              "      <td>0.849598</td>\n",
              "      <td>0.880920</td>\n",
              "      <td>0.848060</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.334000</td>\n",
              "      <td>0.530636</td>\n",
              "      <td>{'precision': 0.8909468839315542, 'recall': 0.944739638682253, 'f1': 0.9170550928402231, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.6513761467889908, 'recall': 0.09184993531694696, 'f1': 0.16099773242630386, 'number': 773}</td>\n",
              "      <td>{'precision': 0.7466666666666667, 'recall': 0.2575896964121435, 'f1': 0.3830369357045144, 'number': 1087}</td>\n",
              "      <td>0.888022</td>\n",
              "      <td>0.893168</td>\n",
              "      <td>0.890587</td>\n",
              "      <td>0.861450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.253900</td>\n",
              "      <td>0.545108</td>\n",
              "      <td>{'precision': 0.9132370167903163, 'recall': 0.9205337111819577, 'f1': 0.9168708469725778, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.4851063829787234, 'recall': 0.14747736093143596, 'f1': 0.22619047619047616, 'number': 773}</td>\n",
              "      <td>{'precision': 0.6326530612244898, 'recall': 0.3137074517019319, 'f1': 0.4194341943419434, 'number': 1087}</td>\n",
              "      <td>0.903692</td>\n",
              "      <td>0.874427</td>\n",
              "      <td>0.888818</td>\n",
              "      <td>0.859309</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.224100</td>\n",
              "      <td>0.552942</td>\n",
              "      <td>{'precision': 0.9090559655596556, 'recall': 0.9308458298894006, 'f1': 0.919821869591428, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.40315315315315314, 'recall': 0.2315653298835705, 'f1': 0.29416598192276094, 'number': 773}</td>\n",
              "      <td>{'precision': 0.5714285714285714, 'recall': 0.39742410303587855, 'f1': 0.4688008681497558, 'number': 1087}</td>\n",
              "      <td>0.891424</td>\n",
              "      <td>0.889757</td>\n",
              "      <td>0.890590</td>\n",
              "      <td>0.864133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.176900</td>\n",
              "      <td>0.573633</td>\n",
              "      <td>{'precision': 0.908678607118149, 'recall': 0.9305309560357382, 'f1': 0.9194749635391346, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.42755344418052255, 'recall': 0.23285899094437257, 'f1': 0.3015075376884422, 'number': 773}</td>\n",
              "      <td>{'precision': 0.576043068640646, 'recall': 0.3937442502299908, 'f1': 0.4677595628415301, 'number': 1087}</td>\n",
              "      <td>0.892135</td>\n",
              "      <td>0.889353</td>\n",
              "      <td>0.890742</td>\n",
              "      <td>0.862420</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.160300</td>\n",
              "      <td>0.593259</td>\n",
              "      <td>{'precision': 0.9026148999962048, 'recall': 0.9360806077065376, 'f1': 0.9190432027204575, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.423963133640553, 'recall': 0.23803363518758086, 'f1': 0.30488815244407624, 'number': 773}</td>\n",
              "      <td>{'precision': 0.5699614890885751, 'recall': 0.40846366145354185, 'f1': 0.4758842443729903, 'number': 1087}</td>\n",
              "      <td>0.885676</td>\n",
              "      <td>0.895258</td>\n",
              "      <td>0.890441</td>\n",
              "      <td>0.864362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.135300</td>\n",
              "      <td>0.635570</td>\n",
              "      <td>{'precision': 0.9014780182490009, 'recall': 0.94103987090172, 'f1': 0.9208342159486992, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.4109014675052411, 'recall': 0.2535575679172057, 'f1': 0.3136, 'number': 773}</td>\n",
              "      <td>{'precision': 0.55627425614489, 'recall': 0.39558417663293466, 'f1': 0.46236559139784944, 'number': 1087}</td>\n",
              "      <td>0.883444</td>\n",
              "      <td>0.899806</td>\n",
              "      <td>0.891550</td>\n",
              "      <td>0.864248</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.109700</td>\n",
              "      <td>0.643016</td>\n",
              "      <td>{'precision': 0.9041843541540328, 'recall': 0.9389538316212067, 'f1': 0.9212411422834083, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.40160642570281124, 'recall': 0.258732212160414, 'f1': 0.31471282454760036, 'number': 773}</td>\n",
              "      <td>{'precision': 0.5397796817625459, 'recall': 0.40570377184912604, 'f1': 0.4632352941176471, 'number': 1087}</td>\n",
              "      <td>0.884400</td>\n",
              "      <td>0.898412</td>\n",
              "      <td>0.891351</td>\n",
              "      <td>0.864676</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-11 21:36:57,506] Trial 3 finished with value: 0.8913510169923227 and parameters: {}. Best is trial 2 with value: 0.8945405592242901.\n",
            "Some weights of AlbertForTokenClassification were not initialized from the model checkpoint at ai4bharat/indic-bert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5490' max='5490' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5490/5490 06:58, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Loc</th>\n",
              "      <th>Org</th>\n",
              "      <th>Per</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.857600</td>\n",
              "      <td>0.564415</td>\n",
              "      <td>{'precision': 0.8638297872340426, 'recall': 0.9268311882552053, 'f1': 0.8942221884671615, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 773}</td>\n",
              "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1087}</td>\n",
              "      <td>0.863830</td>\n",
              "      <td>0.863608</td>\n",
              "      <td>0.863719</td>\n",
              "      <td>0.827533</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.534600</td>\n",
              "      <td>0.694237</td>\n",
              "      <td>{'precision': 0.7966549856642243, 'recall': 0.9842563073168812, 'f1': 0.880574678240048, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.38461538461538464, 'recall': 0.0129366106080207, 'f1': 0.02503128911138924, 'number': 773}</td>\n",
              "      <td>{'precision': 0.5076586433260394, 'recall': 0.21343146274149033, 'f1': 0.3005181347150259, 'number': 1087}</td>\n",
              "      <td>0.792175</td>\n",
              "      <td>0.925991</td>\n",
              "      <td>0.853872</td>\n",
              "      <td>0.803123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.423000</td>\n",
              "      <td>0.486911</td>\n",
              "      <td>{'precision': 0.9133526677525724, 'recall': 0.9048687369622544, 'f1': 0.9090909090909091, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.41762452107279696, 'recall': 0.1410090556274256, 'f1': 0.21083172147001933, 'number': 773}</td>\n",
              "      <td>{'precision': 0.5482695810564663, 'recall': 0.2769089236430543, 'f1': 0.3679706601466993, 'number': 1087}</td>\n",
              "      <td>0.900658</td>\n",
              "      <td>0.858180</td>\n",
              "      <td>0.878906</td>\n",
              "      <td>0.850201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.335800</td>\n",
              "      <td>0.541509</td>\n",
              "      <td>{'precision': 0.9122759051673632, 'recall': 0.919313574999016, 'f1': 0.9157812193687512, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.5443786982248521, 'recall': 0.11901681759379043, 'f1': 0.19532908704883228, 'number': 773}</td>\n",
              "      <td>{'precision': 0.7092731829573935, 'recall': 0.26034958601655933, 'f1': 0.3808882907133243, 'number': 1087}</td>\n",
              "      <td>0.906805</td>\n",
              "      <td>0.870356</td>\n",
              "      <td>0.888207</td>\n",
              "      <td>0.856625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.262800</td>\n",
              "      <td>0.523026</td>\n",
              "      <td>{'precision': 0.8988335576491701, 'recall': 0.946274648718857, 'f1': 0.9219442047742308, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.4375, 'recall': 0.1539456662354463, 'f1': 0.22775119617224876, 'number': 773}</td>\n",
              "      <td>{'precision': 0.6991150442477876, 'recall': 0.2907083716651334, 'f1': 0.41065627030539315, 'number': 1087}</td>\n",
              "      <td>0.890980</td>\n",
              "      <td>0.897679</td>\n",
              "      <td>0.894317</td>\n",
              "      <td>0.865104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.233200</td>\n",
              "      <td>0.546101</td>\n",
              "      <td>{'precision': 0.8994764397905759, 'recall': 0.9466682410359349, 'f1': 0.9224691736820909, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.44416243654822335, 'recall': 0.22639068564036222, 'f1': 0.29991431019708653, 'number': 773}</td>\n",
              "      <td>{'precision': 0.6135734072022161, 'recall': 0.40754369825206993, 'f1': 0.4897733554449973, 'number': 1087}</td>\n",
              "      <td>0.885626</td>\n",
              "      <td>0.904757</td>\n",
              "      <td>0.895089</td>\n",
              "      <td>0.867217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.180900</td>\n",
              "      <td>0.559697</td>\n",
              "      <td>{'precision': 0.9215824796891557, 'recall': 0.9241941197307828, 'f1': 0.9228864520693315, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.36899563318777295, 'recall': 0.2186287192755498, 'f1': 0.27457351746547526, 'number': 773}</td>\n",
              "      <td>{'precision': 0.559322033898305, 'recall': 0.4250229990800368, 'f1': 0.4830109775222164, 'number': 1087}</td>\n",
              "      <td>0.900945</td>\n",
              "      <td>0.884292</td>\n",
              "      <td>0.892541</td>\n",
              "      <td>0.864619</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.156800</td>\n",
              "      <td>0.600604</td>\n",
              "      <td>{'precision': 0.9144820663294854, 'recall': 0.9322627622308812, 'f1': 0.9232868168706634, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.43641618497109824, 'recall': 0.19534282018111254, 'f1': 0.26988382484361034, 'number': 773}</td>\n",
              "      <td>{'precision': 0.564935064935065, 'recall': 0.40018399264029436, 'f1': 0.4684975767366721, 'number': 1087}</td>\n",
              "      <td>0.898397</td>\n",
              "      <td>0.890160</td>\n",
              "      <td>0.894260</td>\n",
              "      <td>0.866332</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.136500</td>\n",
              "      <td>0.625661</td>\n",
              "      <td>{'precision': 0.9048070721250522, 'recall': 0.9386389577675444, 'f1': 0.9214125647167916, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.39555555555555555, 'recall': 0.23027166882276842, 'f1': 0.2910874897792314, 'number': 773}</td>\n",
              "      <td>{'precision': 0.5421115065243179, 'recall': 0.4204231830726771, 'f1': 0.4735751295336788, 'number': 1087}</td>\n",
              "      <td>0.885461</td>\n",
              "      <td>0.897899</td>\n",
              "      <td>0.891636</td>\n",
              "      <td>0.864362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.110100</td>\n",
              "      <td>0.638523</td>\n",
              "      <td>{'precision': 0.9094994814274191, 'recall': 0.931908529145511, 'f1': 0.9205676516329705, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.37475728155339805, 'recall': 0.24967658473479948, 'f1': 0.2996894409937888, 'number': 773}</td>\n",
              "      <td>{'precision': 0.5362485615650172, 'recall': 0.42870285188592455, 'f1': 0.476482617586912, 'number': 1087}</td>\n",
              "      <td>0.887624</td>\n",
              "      <td>0.892507</td>\n",
              "      <td>0.890059</td>\n",
              "      <td>0.862592</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-11 21:43:58,298] Trial 4 finished with value: 0.8900592495062541 and parameters: {}. Best is trial 2 with value: 0.8945405592242901.\n",
            "Some weights of AlbertForTokenClassification were not initialized from the model checkpoint at ai4bharat/indic-bert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1098' max='5490' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1098/5490 01:21 < 05:27, 13.42 it/s, Epoch 2/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Loc</th>\n",
              "      <th>Org</th>\n",
              "      <th>Per</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.858400</td>\n",
              "      <td>0.607546</td>\n",
              "      <td>{'precision': 0.8004271015336828, 'recall': 0.9736686739874838, 'f1': 0.8785893133024346, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 773}</td>\n",
              "      <td>{'precision': 0.4, 'recall': 0.0018399264029438822, 'f1': 0.003663003663003663, 'number': 1087}</td>\n",
              "      <td>0.800362</td>\n",
              "      <td>0.907324</td>\n",
              "      <td>0.850493</td>\n",
              "      <td>0.802981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.530000</td>\n",
              "      <td>0.622141</td>\n",
              "      <td>{'precision': 0.8184868421052631, 'recall': 0.9793364033534065, 'f1': 0.8917160929632484, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.23333333333333334, 'recall': 0.018111254851228976, 'f1': 0.03361344537815125, 'number': 773}</td>\n",
              "      <td>{'precision': 0.49336283185840707, 'recall': 0.20515179392824287, 'f1': 0.2897985705003249, 'number': 1087}</td>\n",
              "      <td>0.812597</td>\n",
              "      <td>0.921223</td>\n",
              "      <td>0.863507</td>\n",
              "      <td>0.820510</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-11 21:45:20,713] Trial 5 pruned. \n",
            "Some weights of AlbertForTokenClassification were not initialized from the model checkpoint at ai4bharat/indic-bert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2196' max='5490' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2196/5490 02:47 < 04:11, 13.10 it/s, Epoch 4/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Loc</th>\n",
              "      <th>Org</th>\n",
              "      <th>Per</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.858400</td>\n",
              "      <td>0.607546</td>\n",
              "      <td>{'precision': 0.8004271015336828, 'recall': 0.9736686739874838, 'f1': 0.8785893133024346, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 773}</td>\n",
              "      <td>{'precision': 0.4, 'recall': 0.0018399264029438822, 'f1': 0.003663003663003663, 'number': 1087}</td>\n",
              "      <td>0.800362</td>\n",
              "      <td>0.907324</td>\n",
              "      <td>0.850493</td>\n",
              "      <td>0.802981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.530800</td>\n",
              "      <td>0.602813</td>\n",
              "      <td>{'precision': 0.8299979921022689, 'recall': 0.9761876648167828, 'f1': 0.8971766535838954, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.17647058823529413, 'recall': 0.015523932729624839, 'f1': 0.028537455410225922, 'number': 773}</td>\n",
              "      <td>{'precision': 0.5186104218362283, 'recall': 0.1922723091076357, 'f1': 0.28053691275167786, 'number': 1087}</td>\n",
              "      <td>0.824400</td>\n",
              "      <td>0.917703</td>\n",
              "      <td>0.868553</td>\n",
              "      <td>0.830331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.421000</td>\n",
              "      <td>0.500999</td>\n",
              "      <td>{'precision': 0.9201368174044465, 'recall': 0.910575825559885, 'f1': 0.9153313550939663, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.38309859154929576, 'recall': 0.1759379042690815, 'f1': 0.24113475177304963, 'number': 773}</td>\n",
              "      <td>{'precision': 0.6196660482374768, 'recall': 0.30726770929162833, 'f1': 0.4108241082410824, 'number': 1087}</td>\n",
              "      <td>0.906594</td>\n",
              "      <td>0.865698</td>\n",
              "      <td>0.885675</td>\n",
              "      <td>0.856825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.339900</td>\n",
              "      <td>0.519016</td>\n",
              "      <td>{'precision': 0.9176470588235294, 'recall': 0.914865981816035, 'f1': 0.9162544099966494, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.6557377049180327, 'recall': 0.1034928848641656, 'f1': 0.1787709497206704, 'number': 773}</td>\n",
              "      <td>{'precision': 0.7110552763819096, 'recall': 0.26034958601655933, 'f1': 0.3811447811447812, 'number': 1087}</td>\n",
              "      <td>0.913230</td>\n",
              "      <td>0.865772</td>\n",
              "      <td>0.888868</td>\n",
              "      <td>0.857824</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-11 21:48:08,954] Trial 6 pruned. \n",
            "Some weights of AlbertForTokenClassification were not initialized from the model checkpoint at ai4bharat/indic-bert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1647' max='5490' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1647/5490 02:09 < 05:01, 12.75 it/s, Epoch 3/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Loc</th>\n",
              "      <th>Org</th>\n",
              "      <th>Per</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.855600</td>\n",
              "      <td>0.568311</td>\n",
              "      <td>{'precision': 0.8720532460771919, 'recall': 0.9230920612429645, 'f1': 0.8968470966138314, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 773}</td>\n",
              "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1087}</td>\n",
              "      <td>0.872021</td>\n",
              "      <td>0.860124</td>\n",
              "      <td>0.866032</td>\n",
              "      <td>0.828903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.534000</td>\n",
              "      <td>0.737639</td>\n",
              "      <td>{'precision': 0.7953886818891118, 'recall': 0.9830361711339395, 'f1': 0.8793127728488945, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.21428571428571427, 'recall': 0.0038809831824062097, 'f1': 0.007623888182973317, 'number': 773}</td>\n",
              "      <td>{'precision': 0.5141065830721003, 'recall': 0.15087396504139836, 'f1': 0.2332859174964438, 'number': 1087}</td>\n",
              "      <td>0.792305</td>\n",
              "      <td>0.922104</td>\n",
              "      <td>0.852291</td>\n",
              "      <td>0.802210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.405000</td>\n",
              "      <td>0.537472</td>\n",
              "      <td>{'precision': 0.9245723172628305, 'recall': 0.8891644035108435, 'f1': 0.9065227423205795, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.4236453201970443, 'recall': 0.111254851228978, 'f1': 0.1762295081967213, 'number': 773}</td>\n",
              "      <td>{'precision': 0.614190687361419, 'recall': 0.2548298068077277, 'f1': 0.3602080624187256, 'number': 1087}</td>\n",
              "      <td>0.914939</td>\n",
              "      <td>0.841823</td>\n",
              "      <td>0.876860</td>\n",
              "      <td>0.843150</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-11 21:50:18,747] Trial 7 pruned. \n",
            "Some weights of AlbertForTokenClassification were not initialized from the model checkpoint at ai4bharat/indic-bert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2196' max='5490' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2196/5490 02:47 < 04:11, 13.12 it/s, Epoch 4/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Loc</th>\n",
              "      <th>Org</th>\n",
              "      <th>Per</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.858400</td>\n",
              "      <td>0.607546</td>\n",
              "      <td>{'precision': 0.8004271015336828, 'recall': 0.9736686739874838, 'f1': 0.8785893133024346, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 773}</td>\n",
              "      <td>{'precision': 0.4, 'recall': 0.0018399264029438822, 'f1': 0.003663003663003663, 'number': 1087}</td>\n",
              "      <td>0.800362</td>\n",
              "      <td>0.907324</td>\n",
              "      <td>0.850493</td>\n",
              "      <td>0.802981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.530800</td>\n",
              "      <td>0.602813</td>\n",
              "      <td>{'precision': 0.8299979921022689, 'recall': 0.9761876648167828, 'f1': 0.8971766535838954, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.17647058823529413, 'recall': 0.015523932729624839, 'f1': 0.028537455410225922, 'number': 773}</td>\n",
              "      <td>{'precision': 0.5186104218362283, 'recall': 0.1922723091076357, 'f1': 0.28053691275167786, 'number': 1087}</td>\n",
              "      <td>0.824400</td>\n",
              "      <td>0.917703</td>\n",
              "      <td>0.868553</td>\n",
              "      <td>0.830331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.421000</td>\n",
              "      <td>0.500999</td>\n",
              "      <td>{'precision': 0.9201368174044465, 'recall': 0.910575825559885, 'f1': 0.9153313550939663, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.38309859154929576, 'recall': 0.1759379042690815, 'f1': 0.24113475177304963, 'number': 773}</td>\n",
              "      <td>{'precision': 0.6196660482374768, 'recall': 0.30726770929162833, 'f1': 0.4108241082410824, 'number': 1087}</td>\n",
              "      <td>0.906594</td>\n",
              "      <td>0.865698</td>\n",
              "      <td>0.885675</td>\n",
              "      <td>0.856825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.339900</td>\n",
              "      <td>0.509154</td>\n",
              "      <td>{'precision': 0.9148492244705141, 'recall': 0.914669185657496, 'f1': 0.9147591962053968, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.6929824561403509, 'recall': 0.10219922380336352, 'f1': 0.17812852311161217, 'number': 773}</td>\n",
              "      <td>{'precision': 0.743455497382199, 'recall': 0.2612695492180313, 'f1': 0.38665759019741325, 'number': 1087}</td>\n",
              "      <td>0.911345</td>\n",
              "      <td>0.865588</td>\n",
              "      <td>0.887877</td>\n",
              "      <td>0.855997</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-11 21:53:06,824] Trial 8 pruned. \n",
            "Some weights of AlbertForTokenClassification were not initialized from the model checkpoint at ai4bharat/indic-bert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1647' max='5490' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1647/5490 02:06 < 04:54, 13.05 it/s, Epoch 3/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Loc</th>\n",
              "      <th>Org</th>\n",
              "      <th>Per</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.858400</td>\n",
              "      <td>0.607546</td>\n",
              "      <td>{'precision': 0.8004271015336828, 'recall': 0.9736686739874838, 'f1': 0.8785893133024346, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 773}</td>\n",
              "      <td>{'precision': 0.4, 'recall': 0.0018399264029438822, 'f1': 0.003663003663003663, 'number': 1087}</td>\n",
              "      <td>0.800362</td>\n",
              "      <td>0.907324</td>\n",
              "      <td>0.850493</td>\n",
              "      <td>0.802981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.528900</td>\n",
              "      <td>0.571531</td>\n",
              "      <td>{'precision': 0.8449750901906888, 'recall': 0.9679615853898532, 'f1': 0.9022967420017611, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.14736842105263157, 'recall': 0.018111254851228976, 'f1': 0.03225806451612903, 'number': 773}</td>\n",
              "      <td>{'precision': 0.3997308209959623, 'recall': 0.2732290708371665, 'f1': 0.32459016393442625, 'number': 1087}</td>\n",
              "      <td>0.831714</td>\n",
              "      <td>0.913338</td>\n",
              "      <td>0.870617</td>\n",
              "      <td>0.833586</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.409200</td>\n",
              "      <td>0.532064</td>\n",
              "      <td>{'precision': 0.9220736876426475, 'recall': 0.8904632581572007, 'f1': 0.9059928318282842, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.5229885057471264, 'recall': 0.11772315653298836, 'f1': 0.19218585005279828, 'number': 773}</td>\n",
              "      <td>{'precision': 0.636568848758465, 'recall': 0.2594296228150874, 'f1': 0.3686274509803922, 'number': 1087}</td>\n",
              "      <td>0.914285</td>\n",
              "      <td>0.843400</td>\n",
              "      <td>0.877413</td>\n",
              "      <td>0.842978</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-11 21:55:13,653] Trial 9 pruned. \n",
            "Some weights of AlbertForTokenClassification were not initialized from the model checkpoint at ai4bharat/indic-bert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5490' max='5490' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5490/5490 07:02, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Loc</th>\n",
              "      <th>Org</th>\n",
              "      <th>Per</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.844100</td>\n",
              "      <td>0.652718</td>\n",
              "      <td>{'precision': 0.7668900227454355, 'recall': 0.9820128311095367, 'f1': 0.8612208971194836, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 773}</td>\n",
              "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1087}</td>\n",
              "      <td>0.766890</td>\n",
              "      <td>0.915025</td>\n",
              "      <td>0.834434</td>\n",
              "      <td>0.774831</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.541900</td>\n",
              "      <td>0.616695</td>\n",
              "      <td>{'precision': 0.8228768806669102, 'recall': 0.97516432479238, 'f1': 0.892571510915772, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.11764705882352941, 'recall': 0.00517464424320828, 'f1': 0.009913258983890954, 'number': 773}</td>\n",
              "      <td>{'precision': 0.47161572052401746, 'recall': 0.19871205151793928, 'f1': 0.2796116504854369, 'number': 1087}</td>\n",
              "      <td>0.816836</td>\n",
              "      <td>0.916713</td>\n",
              "      <td>0.863897</td>\n",
              "      <td>0.822194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.422800</td>\n",
              "      <td>0.538142</td>\n",
              "      <td>{'precision': 0.9288302169658101, 'recall': 0.8778683040107057, 'f1': 0.9026305139619587, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.4018264840182648, 'recall': 0.11384217335058215, 'f1': 0.1774193548387097, 'number': 773}</td>\n",
              "      <td>{'precision': 0.603448275862069, 'recall': 0.3219871205151794, 'f1': 0.4199160167966407, 'number': 1087}</td>\n",
              "      <td>0.916573</td>\n",
              "      <td>0.834048</td>\n",
              "      <td>0.873365</td>\n",
              "      <td>0.838496</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.334900</td>\n",
              "      <td>0.560640</td>\n",
              "      <td>{'precision': 0.9061983629865887, 'recall': 0.9281694021332704, 'f1': 0.9170523041026638, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.5158730158730159, 'recall': 0.08408796895213454, 'f1': 0.14460511679644047, 'number': 773}</td>\n",
              "      <td>{'precision': 0.7345679012345679, 'recall': 0.21895124195032198, 'f1': 0.3373493975903614, 'number': 1087}</td>\n",
              "      <td>0.902240</td>\n",
              "      <td>0.875967</td>\n",
              "      <td>0.888910</td>\n",
              "      <td>0.858424</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.265800</td>\n",
              "      <td>0.566423</td>\n",
              "      <td>{'precision': 0.8924022346368715, 'recall': 0.9430865509505254, 'f1': 0.9170446064642058, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.4358974358974359, 'recall': 0.1539456662354463, 'f1': 0.22753346080305925, 'number': 773}</td>\n",
              "      <td>{'precision': 0.6811320754716981, 'recall': 0.33210671573137074, 'f1': 0.44650587507730366, 'number': 1087}</td>\n",
              "      <td>0.883846</td>\n",
              "      <td>0.896358</td>\n",
              "      <td>0.890058</td>\n",
              "      <td>0.858509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.234500</td>\n",
              "      <td>0.571079</td>\n",
              "      <td>{'precision': 0.8915867158671587, 'recall': 0.9509977565237927, 'f1': 0.9203344315995963, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.44126074498567336, 'recall': 0.19922380336351875, 'f1': 0.2745098039215686, 'number': 773}</td>\n",
              "      <td>{'precision': 0.5455621301775148, 'recall': 0.42410303587856485, 'f1': 0.4772256728778468, 'number': 1087}</td>\n",
              "      <td>0.875698</td>\n",
              "      <td>0.908681</td>\n",
              "      <td>0.891885</td>\n",
              "      <td>0.863334</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.184100</td>\n",
              "      <td>0.581591</td>\n",
              "      <td>{'precision': 0.9, 'recall': 0.9454481048529932, 'f1': 0.922164424055128, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.4564102564102564, 'recall': 0.23027166882276842, 'f1': 0.30610490111779876, 'number': 773}</td>\n",
              "      <td>{'precision': 0.5581683168316832, 'recall': 0.41490340386384544, 'f1': 0.47598944591029024, 'number': 1087}</td>\n",
              "      <td>0.883893</td>\n",
              "      <td>0.904023</td>\n",
              "      <td>0.893845</td>\n",
              "      <td>0.866417</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.167400</td>\n",
              "      <td>0.626232</td>\n",
              "      <td>{'precision': 0.890546528803545, 'recall': 0.949187231865234, 'f1': 0.9189323070474594, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.4376470588235294, 'recall': 0.240620957309185, 'f1': 0.31051752921535897, 'number': 773}</td>\n",
              "      <td>{'precision': 0.5606595995288575, 'recall': 0.43790248390064396, 'f1': 0.4917355371900826, 'number': 1087}</td>\n",
              "      <td>0.873880</td>\n",
              "      <td>0.908717</td>\n",
              "      <td>0.890958</td>\n",
              "      <td>0.860593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.142900</td>\n",
              "      <td>0.631531</td>\n",
              "      <td>{'precision': 0.8950543274634695, 'recall': 0.9402526862675641, 'f1': 0.9170969537593335, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.39723320158102765, 'recall': 0.26002587322121606, 'f1': 0.3143080531665363, 'number': 773}</td>\n",
              "      <td>{'precision': 0.536036036036036, 'recall': 0.43790248390064396, 'f1': 0.48202531645569624, 'number': 1087}</td>\n",
              "      <td>0.874733</td>\n",
              "      <td>0.900943</td>\n",
              "      <td>0.887644</td>\n",
              "      <td>0.858224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.119600</td>\n",
              "      <td>0.638251</td>\n",
              "      <td>{'precision': 0.902084912812737, 'recall': 0.9366316369504467, 'f1': 0.9190337343348717, 'number': 25407}</td>\n",
              "      <td>{'precision': 0.390715667311412, 'recall': 0.2613195342820181, 'f1': 0.3131782945736434, 'number': 773}</td>\n",
              "      <td>{'precision': 0.5383734249713631, 'recall': 0.43238270469181234, 'f1': 0.47959183673469385, 'number': 1087}</td>\n",
              "      <td>0.881131</td>\n",
              "      <td>0.897385</td>\n",
              "      <td>0.889184</td>\n",
              "      <td>0.860536</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2/2 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.23289106786251068, 'eval_LOC': {'precision': 0.952286282306163, 'recall': 0.9637826961770624, 'f1': 0.9580000000000001, 'number': 497}, 'eval_ORG': {'precision': 0.3333333333333333, 'recall': 0.2222222222222222, 'f1': 0.26666666666666666, 'number': 9}, 'eval_PER': {'precision': 0.5555555555555556, 'recall': 0.45454545454545453, 'f1': 0.5, 'number': 11}, 'eval_precision': 0.9382239382239382, 'eval_recall': 0.9400386847195358, 'eval_f1': 0.9391304347826087, 'eval_accuracy': 0.9402985074626866, 'eval_runtime': 0.1032, 'eval_samples_per_second': 494.166, 'eval_steps_per_second': 19.379, 'epoch': 10.0}\n"
          ]
        }
      ]
    }
  ]
}
